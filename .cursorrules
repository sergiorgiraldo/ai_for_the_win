# AI for the Win - Cursor Rules

# Security AI Training Program

## Project Context

This is a hands-on training program for security practitioners building AI-powered tools.
It contains 40+ labs (including 8 intro labs and 12 bridge labs), 4 capstone projects, and 15 CTF challenges
covering threat detection, incident response, and security automation.

## Lab Structure

Labs follow this pattern:

labXX-topic-name/
├── README.md # Objectives, instructions, hints
├── starter/ # Starter code with TODOs
│ └── main.py
├── solution/ # Reference implementation
│ └── main.py
├── data/ # Sample datasets
└── tests/
└── test\_\*.py

## Lab Progression

- **Labs 00a-00g**: Intro (Python, ML concepts, prompting, visualization, APIs) - no API keys needed
- **Labs 01-03**: ML foundations (classification, clustering, anomaly detection) - no API keys
- **Lab 03b**: Bridge lab - ML vs LLM decision making
- **Labs 04-07**: LLM basics (prompts, agents, RAG, code generation) - requires API key
- **Labs 04b, 06a, 07a, 07b**: Bridge labs (first agent, embeddings, binary basics, Sigma)
- **Labs 08-10**: Advanced (vuln scanner, pipelines, copilots)
- **Labs 09b, 10a**: Bridge labs (monitoring AI, DFIR fundamentals)
- **Labs 11-16**: Expert DFIR (ransomware, memory forensics, C2, lateral movement, threat actors)
- **Labs 11a, 16b**: Bridge labs (ransomware fundamentals, AI-powered threat actors)
- **Labs 17-20**: Expert AI Security (adversarial ML, fine-tuning, cloud security, LLM red teaming)
- **Labs 17a, 19a, 20b**: Bridge labs (ML security intro, cloud fundamentals, purple team AI)

## Code Style Requirements

- Python 3.10+ with full type hints
- Line length: 100 characters (Black formatter)
- Follow PEP 8 and PEP 257 (docstrings)
- Use async/await for I/O operations where appropriate
- Imports sorted with isort (profile: black)

## Security Requirements (CRITICAL)

- NEVER log sensitive data (passwords, API keys, PII, credentials)
- NEVER store secrets in code - use environment variables via python-dotenv
- ALWAYS validate and sanitize external inputs
- ALWAYS use parameterized queries for databases
- NEVER use shell=True with user input
- NEVER disable SSL certificate verification in production
- ALWAYS check authentication before authorization

## Multi-Provider LLM Support

All LLM labs support multiple providers. Use environment variables:

- `ANTHROPIC_API_KEY` - Claude (recommended)
- `OPENAI_API_KEY` - GPT-4
- `GOOGLE_API_KEY` - Gemini
- Ollama for local models (no key needed)

## Preferred Libraries

| Purpose           | Library                                                   |
| ----------------- | --------------------------------------------------------- |
| LLM Operations    | langchain, langchain-anthropic, langchain-openai, litellm |
| Structured Output | instructor, pydantic                                      |
| Vector DB         | chromadb, sentence-transformers                           |
| HTTP Client       | httpx (async), requests                                   |
| Data Validation   | pydantic v2                                               |
| Logging           | loguru or rich                                            |
| Security Tools    | yara-python, pefile                                       |
| UI                | gradio, streamlit                                         |
| Testing           | pytest, pytest-cov                                        |

## Output Formatting

When analyzing security data:

- Include MITRE ATT&CK IDs when relevant (e.g., T1059.001)
- Reference CVE IDs for vulnerabilities
- Use CWE classifications for code weaknesses
- Format IOCs in defanged notation (hxxp://, [.])
- Map findings to OWASP Top 10 where applicable

## Analysis Guidelines

When analyzing potentially malicious code:

- Explain what the code does in detail
- Identify malicious capabilities
- Map to MITRE ATT&CK techniques
- Extract IOCs (indicators of compromise)
- NEVER enhance or weaponize malicious functionality

## Testing Requirements

- Use pytest with markers: slow, integration, requires_api
- Run tests: `pytest tests/ -v`
- Skip slow: `pytest -m "not slow"`
- Skip API tests: `pytest -m "not requires_api"`

## File Organization

labs/ # 40+ hands-on labs with starter/solution code
capstone-projects/ # 4 comprehensive projects
templates/ # Reusable agent, prompt, and visualization templates
resources/ # Tools, datasets, cheatsheets
mcp-servers/ # MCP server implementations
docs/guides/ # Troubleshooting and configuration guides
notebooks/ # Jupyter notebooks (Colab-ready)
shared/ # Shared utilities (llm_config, ioc_utils)
tests/ # Test files for all labs

## Common Commands

# Verify setup

python scripts/verify_setup.py

# Run all tests

pytest tests/ -v

# Run specific lab test

pytest tests/test_lab01_phishing_classifier.py -v

# Format code

black . && isort .

# Security scan

bandit -r labs/ -ll

# Run a lab solution

python labs/lab01-phishing-classifier/solution/main.py

## Response Guidelines

- When helping with lab exercises, guide toward the solution rather than giving it directly
- Reference the lab's README.md for context and learning objectives
- Suggest testing approaches that match pytest markers
- Consider which labs require API keys when troubleshooting
- Check shared/llm_config.py for multi-provider LLM setup patterns
