{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14: C2 Traffic Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab14_c2_traffic.ipynb)\n",
    "\n",
    "Detect command-and-control communications using ML and AI.\n",
    "\n",
    "## Learning Objectives\n",
    "- Beaconing detection algorithms\n",
    "- DNS tunneling identification\n",
    "- JA3/JA3S fingerprinting\n",
    "- LLM-powered traffic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn anthropic -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Beaconing Detection\n",
    "\n",
    "C2 beacons have regular intervals with low jitter (variation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample beacon data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Normal traffic (random intervals)\n",
    "normal_intervals = np.random.exponential(60, 50)  # Random, exponential distribution\n",
    "\n",
    "# C2 beacon (regular intervals with small jitter)\n",
    "beacon_intervals = 30 + np.random.normal(0, 2, 50)  # ~30 seconds with small jitter\n",
    "\n",
    "def calculate_beacon_score(intervals: np.ndarray) -> Dict:\n",
    "    \"\"\"Calculate beaconing probability score.\"\"\"\n",
    "    mean_interval = np.mean(intervals)\n",
    "    std_interval = np.std(intervals)\n",
    "    jitter = std_interval / mean_interval if mean_interval > 0 else 1\n",
    "    \n",
    "    # Low jitter = high beacon probability\n",
    "    beacon_score = max(0, 1 - (jitter * 2))\n",
    "    \n",
    "    return {\n",
    "        \"mean_interval\": round(mean_interval, 2),\n",
    "        \"std_interval\": round(std_interval, 2),\n",
    "        \"jitter\": round(jitter, 4),\n",
    "        \"beacon_score\": round(beacon_score, 2),\n",
    "        \"is_beacon\": beacon_score > 0.7\n",
    "    }\n",
    "\n",
    "print(\"Normal Traffic:\")\n",
    "print(calculate_beacon_score(normal_intervals))\n",
    "print(\"\\nC2 Beacon:\")\n",
    "print(calculate_beacon_score(beacon_intervals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DNS Tunneling Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DNS queries\n",
    "normal_dns = [\n",
    "    \"www.google.com\",\n",
    "    \"api.github.com\",\n",
    "    \"cdn.example.com\",\n",
    "]\n",
    "\n",
    "tunneling_dns = [\n",
    "    \"aGVsbG8gd29ybGQgdGhpcyBpcyBhIHRlc3Q.evil.com\",\n",
    "    \"c29tZSBlbmNvZGVkIGRhdGEgaGVyZQ.evil.com\",\n",
    "    \"bW9yZSBkYXRhIGV4ZmlsdHJhdGlvbg.evil.com\",\n",
    "]\n",
    "\n",
    "def analyze_dns_query(query: str) -> Dict:\n",
    "    \"\"\"Analyze DNS query for tunneling indicators.\"\"\"\n",
    "    parts = query.split('.')\n",
    "    subdomain = parts[0] if len(parts) > 2 else \"\"\n",
    "    \n",
    "    # Calculate entropy of subdomain\n",
    "    if subdomain:\n",
    "        freq = Counter(subdomain)\n",
    "        probs = [f/len(subdomain) for f in freq.values()]\n",
    "        entropy = -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "    else:\n",
    "        entropy = 0\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"subdomain_length\": len(subdomain),\n",
    "        \"entropy\": round(entropy, 2),\n",
    "        \"is_suspicious\": len(subdomain) > 30 or entropy > 4.0\n",
    "    }\n",
    "\n",
    "print(\"Normal DNS:\")\n",
    "for q in normal_dns:\n",
    "    print(analyze_dns_query(q))\n",
    "\n",
    "print(\"\\nDNS Tunneling:\")\n",
    "for q in tunneling_dns:\n",
    "    print(analyze_dns_query(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JA3 Fingerprinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known malicious JA3 hashes (examples)\n",
    "MALICIOUS_JA3 = {\n",
    "    \"e7d705a3286e19ea42f587b344ee6865\": \"Cobalt Strike\",\n",
    "    \"72a589da586844d7f0818ce684948eea\": \"Metasploit\",\n",
    "    \"a0e9f5d64349fb13191bc781f81f42e1\": \"Trickbot\",\n",
    "}\n",
    "\n",
    "def check_ja3(ja3_hash: str) -> Dict:\n",
    "    \"\"\"Check JA3 hash against known malware.\"\"\"\n",
    "    if ja3_hash in MALICIOUS_JA3:\n",
    "        return {\n",
    "            \"ja3\": ja3_hash,\n",
    "            \"status\": \"MALICIOUS\",\n",
    "            \"malware_family\": MALICIOUS_JA3[ja3_hash]\n",
    "        }\n",
    "    return {\n",
    "        \"ja3\": ja3_hash,\n",
    "        \"status\": \"UNKNOWN\",\n",
    "        \"malware_family\": None\n",
    "    }\n",
    "\n",
    "# Test\n",
    "print(check_ja3(\"e7d705a3286e19ea42f587b344ee6865\"))\n",
    "print(check_ja3(\"abc123def456\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traffic Pattern Classification with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic network flow data\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_flow_data(n_samples: int, is_c2: bool) -> np.ndarray:\n",
    "    \"\"\"Generate synthetic network flow features.\"\"\"\n",
    "    if is_c2:\n",
    "        # C2: Regular intervals, consistent sizes, low ports\n",
    "        intervals = np.random.normal(30, 5, n_samples)\n",
    "        sizes = np.random.normal(500, 50, n_samples)\n",
    "        ports = np.random.choice([80, 443, 8080], n_samples)\n",
    "    else:\n",
    "        # Normal: Random intervals, varied sizes\n",
    "        intervals = np.random.exponential(60, n_samples)\n",
    "        sizes = np.random.exponential(1000, n_samples)\n",
    "        ports = np.random.randint(1024, 65535, n_samples)\n",
    "    \n",
    "    return np.column_stack([intervals, sizes, ports])\n",
    "\n",
    "# Create dataset\n",
    "X_c2 = generate_flow_data(100, is_c2=True)\n",
    "X_normal = generate_flow_data(100, is_c2=False)\n",
    "X = np.vstack([X_c2, X_normal])\n",
    "y = np.array([1]*100 + [0]*100)\n",
    "\n",
    "# Train classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model Accuracy: {clf.score(X_test, y_test):.2%}\")\n",
    "print(f\"Feature Importance: {dict(zip(['interval', 'size', 'port'], clf.feature_importances_.round(2)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM-Powered Traffic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "import json\n",
    "\n",
    "def analyze_traffic_with_llm(flows: List[Dict]) -> str:\n",
    "    \"\"\"Use LLM to analyze network traffic patterns.\"\"\"\n",
    "    \n",
    "    client = Anthropic()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze these network flows for C2 communication patterns.\n",
    "    \n",
    "    FLOWS:\n",
    "    {json.dumps(flows, indent=2)}\n",
    "    \n",
    "    Look for:\n",
    "    1. Beaconing patterns (regular intervals)\n",
    "    2. Unusual port usage\n",
    "    3. Suspicious payload sizes\n",
    "    4. Known C2 indicators\n",
    "    \n",
    "    Provide MITRE ATT&CK technique mappings.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1500,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.content[0].text\n",
    "\n",
    "# Sample flows for analysis\n",
    "sample_flows = [\n",
    "    {\"src\": \"192.168.1.100\", \"dst\": \"45.33.32.156\", \"port\": 443, \"bytes\": 512, \"interval\": 30},\n",
    "    {\"src\": \"192.168.1.100\", \"dst\": \"45.33.32.156\", \"port\": 443, \"bytes\": 508, \"interval\": 31},\n",
    "    {\"src\": \"192.168.1.100\", \"dst\": \"45.33.32.156\", \"port\": 443, \"bytes\": 515, \"interval\": 29},\n",
    "]\n",
    "\n",
    "# Uncomment to run with API key\n",
    "# analysis = analyze_traffic_with_llm(sample_flows)\n",
    "# print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Beaconing**: Low jitter in connection intervals\n",
    "2. **DNS Tunneling**: Long subdomains, high entropy\n",
    "3. **JA3**: TLS fingerprints identify malware families\n",
    "4. **ML Classification**: Combine features for detection\n",
    "\n",
    "## Next Steps\n",
    "- **Lab 15**: Lateral Movement Detection\n",
    "- **Lab 16**: Threat Actor Profiling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
