{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 04: LLM-Powered Log Analysis\n",
    "\n",
    "Use Large Language Models to analyze security logs and extract insights.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab04_llm_log_analysis.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "- Log parsing and normalization\n",
    "- Using LLMs for log interpretation\n",
    "- Pattern extraction and summarization\n",
    "- Anomaly explanation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment for Colab)\n",
    "# !pip install anthropic pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Set your API key\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'your-api-key-here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Log Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LogEntry:\n",
    "    \"\"\"Parsed log entry.\"\"\"\n",
    "    timestamp: str\n",
    "    source: str\n",
    "    event_type: str\n",
    "    severity: str\n",
    "    message: str\n",
    "    raw: str\n",
    "\n",
    "# Sample security logs\n",
    "SAMPLE_LOGS = \"\"\"\n",
    "2024-01-15 09:15:23 AUTH Failed login attempt for user admin from 192.168.1.100\n",
    "2024-01-15 09:15:24 AUTH Failed login attempt for user admin from 192.168.1.100\n",
    "2024-01-15 09:15:25 AUTH Failed login attempt for user admin from 192.168.1.100\n",
    "2024-01-15 09:15:26 AUTH Account locked: admin after 3 failed attempts\n",
    "2024-01-15 09:17:00 FIREWALL Blocked connection from 10.0.0.50 to 203.0.113.5:4444\n",
    "2024-01-15 09:17:01 FIREWALL Blocked connection from 10.0.0.50 to 203.0.113.5:4444\n",
    "2024-01-15 09:18:00 PROCESS Suspicious process spawned: powershell.exe -enc SGVsbG8gV29ybGQ=\n",
    "2024-01-15 09:18:05 NETWORK Unusual DNS query: malware-c2.evil.com\n",
    "2024-01-15 09:19:00 FILE New executable created: C:\\\\Users\\\\Admin\\\\Downloads\\\\update.exe\n",
    "2024-01-15 09:20:00 PROCESS Process injection detected: explorer.exe -> svchost.exe\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Log Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogParser:\n",
    "    \"\"\"Parse various log formats.\"\"\"\n",
    "    \n",
    "    PATTERNS = {\n",
    "        'standard': r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) (\\w+) (.+)',\n",
    "        'syslog': r'(\\w{3}\\s+\\d+\\s+\\d{2}:\\d{2}:\\d{2}) (\\S+) (\\S+): (.+)'\n",
    "    }\n",
    "    \n",
    "    SEVERITY_KEYWORDS = {\n",
    "        'critical': ['injection', 'ransomware', 'exfiltration'],\n",
    "        'high': ['failed', 'blocked', 'suspicious', 'malware'],\n",
    "        'medium': ['unusual', 'warning', 'locked'],\n",
    "        'low': ['info', 'success', 'allowed']\n",
    "    }\n",
    "    \n",
    "    def parse(self, raw_logs: str) -> List[LogEntry]:\n",
    "        entries = []\n",
    "        for line in raw_logs.strip().split('\\n'):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            entry = self._parse_line(line)\n",
    "            if entry:\n",
    "                entries.append(entry)\n",
    "        return entries\n",
    "    \n",
    "    def _parse_line(self, line: str) -> LogEntry:\n",
    "        match = re.match(self.PATTERNS['standard'], line)\n",
    "        if match:\n",
    "            timestamp, source, message = match.groups()\n",
    "            return LogEntry(\n",
    "                timestamp=timestamp,\n",
    "                source=source,\n",
    "                event_type=source,\n",
    "                severity=self._classify_severity(message),\n",
    "                message=message,\n",
    "                raw=line\n",
    "            )\n",
    "        return None\n",
    "    \n",
    "    def _classify_severity(self, message: str) -> str:\n",
    "        message_lower = message.lower()\n",
    "        for severity, keywords in self.SEVERITY_KEYWORDS.items():\n",
    "            if any(kw in message_lower for kw in keywords):\n",
    "                return severity\n",
    "        return 'info'\n",
    "\n",
    "# Parse logs\n",
    "parser = LogParser()\n",
    "entries = parser.parse(SAMPLE_LOGS)\n",
    "\n",
    "print(f\"Parsed {len(entries)} log entries\")\n",
    "for entry in entries[:3]:\n",
    "    print(f\"  [{entry.severity.upper()}] {entry.source}: {entry.message[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. LLM Log Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMLogAnalyzer:\n",
    "    \"\"\"Use LLM to analyze security logs.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            from anthropic import Anthropic\n",
    "            self.client = Anthropic()\n",
    "            self.available = True\n",
    "        except:\n",
    "            self.available = False\n",
    "            print(\"Note: Anthropic client not available. Using mock responses.\")\n",
    "    \n",
    "    def analyze_logs(self, entries: List[LogEntry]) -> Dict:\n",
    "        \"\"\"Analyze log entries and generate insights.\"\"\"\n",
    "        logs_text = \"\\n\".join([e.raw for e in entries])\n",
    "        \n",
    "        prompt = f\"\"\"Analyze these security logs and provide:\n",
    "1. Summary of events\n",
    "2. Potential security incidents detected\n",
    "3. Attack timeline if applicable\n",
    "4. Recommended actions\n",
    "\n",
    "LOGS:\n",
    "{logs_text}\n",
    "\n",
    "Provide a structured analysis.\"\"\"\n",
    "        \n",
    "        if self.available:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=1024,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return {\"analysis\": response.content[0].text}\n",
    "        else:\n",
    "            return self._mock_analysis(entries)\n",
    "    \n",
    "    def _mock_analysis(self, entries: List[LogEntry]) -> Dict:\n",
    "        \"\"\"Mock analysis for demo purposes.\"\"\"\n",
    "        return {\n",
    "            \"analysis\": \"\"\"\n",
    "## Security Log Analysis\n",
    "\n",
    "### Summary\n",
    "The logs show a potential attack sequence spanning approximately 5 minutes.\n",
    "\n",
    "### Incidents Detected\n",
    "1. **Brute Force Attack** (09:15:23 - 09:15:26)\n",
    "   - 3 failed login attempts for 'admin' from 192.168.1.100\n",
    "   - Account was locked after threshold reached\n",
    "\n",
    "2. **C2 Communication Attempt** (09:17:00 - 09:18:05)\n",
    "   - Blocked outbound connection to 203.0.113.5:4444\n",
    "   - DNS query to known malware domain: malware-c2.evil.com\n",
    "\n",
    "3. **Malware Execution** (09:18:00 - 09:20:00)\n",
    "   - Encoded PowerShell execution\n",
    "   - New executable dropped\n",
    "   - Process injection detected\n",
    "\n",
    "### Recommended Actions\n",
    "1. Isolate affected hosts (10.0.0.50, workstation with admin user)\n",
    "2. Block C2 IP 203.0.113.5 at perimeter\n",
    "3. Analyze dropped executable update.exe\n",
    "4. Reset admin credentials after investigation\n",
    "5. Check for lateral movement\n",
    "\"\"\"\n",
    "        }\n",
    "\n",
    "# Analyze logs\n",
    "analyzer = LLMLogAnalyzer()\n",
    "result = analyzer.analyze_logs(entries)\n",
    "print(result['analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Pattern Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternDetector:\n",
    "    \"\"\"Detect common attack patterns in logs.\"\"\"\n",
    "    \n",
    "    ATTACK_PATTERNS = {\n",
    "        'brute_force': {\n",
    "            'keywords': ['failed login', 'authentication failed'],\n",
    "            'threshold': 3,\n",
    "            'window_seconds': 60\n",
    "        },\n",
    "        'c2_communication': {\n",
    "            'keywords': ['blocked connection', 'suspicious dns', 'malware'],\n",
    "            'ports': [4444, 8888, 31337, 6667]\n",
    "        },\n",
    "        'lateral_movement': {\n",
    "            'keywords': ['psexec', 'wmi', 'remote', 'injection']\n",
    "        },\n",
    "        'data_exfiltration': {\n",
    "            'keywords': ['large transfer', 'upload', 'exfil']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def detect(self, entries: List[LogEntry]) -> List[Dict]:\n",
    "        detections = []\n",
    "        \n",
    "        for pattern_name, config in self.ATTACK_PATTERNS.items():\n",
    "            matches = self._find_matches(entries, config)\n",
    "            if matches:\n",
    "                detections.append({\n",
    "                    'pattern': pattern_name,\n",
    "                    'count': len(matches),\n",
    "                    'entries': matches[:5]  # First 5 matches\n",
    "                })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def _find_matches(self, entries: List[LogEntry], config: Dict) -> List[LogEntry]:\n",
    "        matches = []\n",
    "        for entry in entries:\n",
    "            message_lower = entry.message.lower()\n",
    "            if any(kw in message_lower for kw in config.get('keywords', [])):\n",
    "                matches.append(entry)\n",
    "        return matches\n",
    "\n",
    "# Detect patterns\n",
    "detector = PatternDetector()\n",
    "patterns = detector.detect(entries)\n",
    "\n",
    "print(\"\\nDetected Attack Patterns:\")\n",
    "print(\"=\" * 40)\n",
    "for p in patterns:\n",
    "    print(f\"\\n{p['pattern'].upper()} ({p['count']} events)\")\n",
    "    for entry in p['entries']:\n",
    "        print(f\"  - [{entry.timestamp}] {entry.message[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Log Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df = pd.DataFrame([{\n",
    "    'timestamp': e.timestamp,\n",
    "    'source': e.source,\n",
    "    'severity': e.severity,\n",
    "    'message': e.message\n",
    "} for e in entries])\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Events by source\n",
    "df['source'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Events by Source')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Events by severity\n",
    "severity_order = ['critical', 'high', 'medium', 'low', 'info']\n",
    "severity_colors = {'critical': 'red', 'high': 'orange', 'medium': 'yellow', 'low': 'green', 'info': 'blue'}\n",
    "severity_counts = df['severity'].value_counts()\n",
    "colors = [severity_colors.get(s, 'gray') for s in severity_counts.index]\n",
    "severity_counts.plot(kind='bar', ax=axes[1], color=colors)\n",
    "axes[1].set_title('Events by Severity')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we built an LLM-powered log analysis system:\n",
    "\n",
    "1. **Log Parsing** - Extracted structured data from raw logs\n",
    "2. **LLM Analysis** - Used Claude to generate security insights\n",
    "3. **Pattern Detection** - Identified common attack patterns\n",
    "4. **Visualization** - Created dashboards for log statistics\n",
    "\n",
    "### Key Takeaways:\n",
    "- LLMs excel at summarizing and correlating log events\n",
    "- Combine rule-based detection with LLM analysis\n",
    "- Structured prompts yield better results\n",
    "- Pre-filter logs to reduce token usage\n",
    "\n",
    "### Next Steps:\n",
    "1. Add real-time log streaming\n",
    "2. Build query interface for log search\n",
    "3. Create automated alerting pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
