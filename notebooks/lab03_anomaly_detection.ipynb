{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 03: Network Anomaly Detection\n",
    "\n",
    "Build an anomaly detection system for network traffic using Isolation Forest and One-Class SVM.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab03_anomaly_detection.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "- Network flow feature engineering\n",
    "- Isolation Forest for anomaly detection\n",
    "- One-Class SVM and Local Outlier Factor\n",
    "- Precision-Recall evaluation for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment for Colab)\n",
    "# !pip install scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Generate Network Flow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic network flow data\n",
    "n_normal = 900\n",
    "n_anomaly = 100\n",
    "\n",
    "# Normal traffic\n",
    "normal_data = {\n",
    "    'bytes_sent': np.random.lognormal(8, 1, n_normal),\n",
    "    'bytes_recv': np.random.lognormal(9, 1.2, n_normal),\n",
    "    'packets_sent': np.random.poisson(50, n_normal),\n",
    "    'packets_recv': np.random.poisson(80, n_normal),\n",
    "    'duration': np.random.exponential(5, n_normal),\n",
    "    'dst_port': np.random.choice([80, 443, 22, 53, 8080], n_normal, p=[0.3, 0.4, 0.1, 0.1, 0.1]),\n",
    "    'protocol': np.random.choice(['TCP', 'UDP'], n_normal, p=[0.85, 0.15]),\n",
    "    'label': 0\n",
    "}\n",
    "\n",
    "# Anomalous traffic (C2, exfiltration, scanning)\n",
    "anomaly_data = {\n",
    "    'bytes_sent': np.random.lognormal(12, 2, n_anomaly),  # Larger transfers\n",
    "    'bytes_recv': np.random.lognormal(6, 0.5, n_anomaly),  # Small responses\n",
    "    'packets_sent': np.random.poisson(500, n_anomaly),  # Many packets\n",
    "    'packets_recv': np.random.poisson(20, n_anomaly),\n",
    "    'duration': np.random.uniform(0.001, 0.5, n_anomaly),  # Short bursts\n",
    "    'dst_port': np.random.choice([4444, 8888, 31337, 6667], n_anomaly),  # Suspicious ports\n",
    "    'protocol': np.random.choice(['TCP', 'UDP'], n_anomaly, p=[0.5, 0.5]),\n",
    "    'label': 1\n",
    "}\n",
    "\n",
    "df_normal = pd.DataFrame(normal_data)\n",
    "df_anomaly = pd.DataFrame(anomaly_data)\n",
    "df = pd.concat([df_normal, df_anomaly], ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer network features\n",
    "df['duration'] = df['duration'].clip(lower=0.001)\n",
    "\n",
    "# Total bytes and packets\n",
    "df['total_bytes'] = df['bytes_sent'] + df['bytes_recv']\n",
    "df['total_packets'] = df['packets_sent'] + df['packets_recv']\n",
    "\n",
    "# Rate features\n",
    "df['bytes_per_second'] = df['total_bytes'] / df['duration']\n",
    "df['packets_per_second'] = df['total_packets'] / df['duration']\n",
    "\n",
    "# Ratio features\n",
    "df['bytes_ratio'] = df['bytes_sent'] / (df['total_bytes'] + 1)\n",
    "df['packets_ratio'] = df['packets_sent'] / (df['total_packets'] + 1)\n",
    "\n",
    "# Bytes per packet\n",
    "df['bytes_per_packet'] = df['total_bytes'] / (df['total_packets'] + 1)\n",
    "\n",
    "# Port features\n",
    "df['is_well_known_port'] = (df['dst_port'] < 1024).astype(int)\n",
    "df['is_suspicious_port'] = df['dst_port'].isin([4444, 8888, 31337, 6667, 1337]).astype(int)\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "print(df[['bytes_per_second', 'packets_per_second', 'bytes_ratio', 'bytes_per_packet']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "features_to_plot = ['bytes_per_second', 'packets_per_second', 'bytes_ratio', 'duration']\n",
    "for ax, feature in zip(axes.flatten(), features_to_plot):\n",
    "    for label, color in [(0, 'green'), (1, 'red')]:\n",
    "        subset = df[df['label'] == label][feature]\n",
    "        ax.hist(subset, alpha=0.5, label=f\"{'Normal' if label==0 else 'Anomaly'}\", \n",
    "                bins=30, color=color, density=True)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'{feature} Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Prepare Features for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for anomaly detection\n",
    "feature_cols = [\n",
    "    'bytes_per_second', 'packets_per_second', \n",
    "    'bytes_ratio', 'packets_ratio', \n",
    "    'bytes_per_packet', 'duration',\n",
    "    'is_well_known_port', 'is_suspicious_port'\n",
    "]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Use RobustScaler for outlier-robust scaling\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.1,  # Expected proportion of anomalies\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Predict: -1 for anomaly, 1 for normal\n",
    "iso_pred = iso_forest.fit_predict(X_scaled)\n",
    "\n",
    "# Convert to binary (1 for anomaly, 0 for normal)\n",
    "iso_pred_binary = (iso_pred == -1).astype(int)\n",
    "\n",
    "print(\"Isolation Forest Results:\")\n",
    "print(f\"Predicted anomalies: {iso_pred_binary.sum()}\")\n",
    "print(f\"Actual anomalies: {y.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Isolation Forest\n",
    "precision = precision_score(y, iso_pred_binary)\n",
    "recall = recall_score(y, iso_pred_binary)\n",
    "f1 = f1_score(y, iso_pred_binary)\n",
    "\n",
    "print(\"Isolation Forest Metrics:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y, iso_pred_binary)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Isolation Forest Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train One-Class SVM (on normal data only for proper one-class learning)\n",
    "# In practice, you'd train only on normal traffic\n",
    "ocsvm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    nu=0.1  # Upper bound on fraction of outliers\n",
    ")\n",
    "\n",
    "ocsvm_pred = ocsvm.fit_predict(X_scaled)\n",
    "ocsvm_pred_binary = (ocsvm_pred == -1).astype(int)\n",
    "\n",
    "print(\"One-Class SVM Results:\")\n",
    "print(f\"Predicted anomalies: {ocsvm_pred_binary.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Local Outlier Factor\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=0.1\n",
    ")\n",
    "\n",
    "lof_pred = lof.fit_predict(X_scaled)\n",
    "lof_pred_binary = (lof_pred == -1).astype(int)\n",
    "\n",
    "print(\"LOF Results:\")\n",
    "print(f\"Predicted anomalies: {lof_pred_binary.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "models = {\n",
    "    'Isolation Forest': iso_pred_binary,\n",
    "    'One-Class SVM': ocsvm_pred_binary,\n",
    "    'Local Outlier Factor': lof_pred_binary\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, pred in models.items():\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Precision': precision_score(y, pred),\n",
    "        'Recall': recall_score(y, pred),\n",
    "        'F1': f1_score(y, pred)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Plot comparison\n",
    "results_df.set_index('Model')[['Precision', 'Recall', 'F1']].plot(kind='bar', figsize=(10, 5))\n",
    "plt.title('Anomaly Detection Model Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 8. Anomaly Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anomaly scores from Isolation Forest\n",
    "anomaly_scores = -iso_forest.score_samples(X_scaled)\n",
    "df['anomaly_score'] = anomaly_scores\n",
    "\n",
    "# Plot score distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for label, color, name in [(0, 'green', 'Normal'), (1, 'red', 'Anomaly')]:\n",
    "    subset = df[df['label'] == label]['anomaly_score']\n",
    "    ax.hist(subset, alpha=0.5, label=name, bins=30, color=color, density=True)\n",
    "\n",
    "ax.axvline(x=np.percentile(anomaly_scores, 90), color='black', linestyle='--', \n",
    "           label='90th percentile threshold')\n",
    "ax.set_xlabel('Anomaly Score')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Anomaly Score Distribution')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top anomalies\n",
    "print(\"Top 10 Most Anomalous Flows:\")\n",
    "top_anomalies = df.nlargest(10, 'anomaly_score')[[\n",
    "    'bytes_sent', 'bytes_recv', 'dst_port', 'duration', 'anomaly_score', 'label'\n",
    "]]\n",
    "print(top_anomalies.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we built a network anomaly detection system using:\n",
    "- **Feature engineering** for network flows (rates, ratios, port analysis)\n",
    "- **Isolation Forest** for efficient anomaly detection\n",
    "- **One-Class SVM** for boundary-based detection\n",
    "- **Local Outlier Factor** for density-based detection\n",
    "\n",
    "### Key Takeaways:\n",
    "- Isolation Forest is fast and effective for large datasets\n",
    "- Feature engineering is crucial (bytes/second, packets/second)\n",
    "- Contamination parameter should match expected anomaly rate\n",
    "- Combine multiple detectors for robustness\n",
    "\n",
    "### Next Steps:\n",
    "1. Add time-based features (hour of day, day of week)\n",
    "2. Implement sliding window aggregation\n",
    "3. Build real-time detection pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
