{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 18: Fine-Tuning for Security\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab18_fine_tuning.ipynb)\n",
    "\n",
    "Build custom security-focused AI models through fine-tuning.\n",
    "\n",
    "## Learning Objectives\n",
    "- Custom embedding training\n",
    "- LoRA fine-tuning concepts\n",
    "- Security-specific evaluation\n",
    "- Model deployment strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers scikit-learn pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Security Text Embeddings\n",
    "\n",
    "Standard embeddings may not capture security-specific semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Security-related texts\n",
    "security_texts = [\n",
    "    \"PowerShell encoded command execution detected\",\n",
    "    \"Base64 encoded PowerShell payload found\",\n",
    "    \"User logged in from new location\",\n",
    "    \"Failed SSH authentication attempt\",\n",
    "    \"Brute force password attack detected\",\n",
    "]\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = model.encode(security_texts)\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"Similarity Matrix:\")\n",
    "df_sim = pd.DataFrame(similarity_matrix, \n",
    "                       index=[f\"T{i}\" for i in range(len(security_texts))],\n",
    "                       columns=[f\"T{i}\" for i in range(len(security_texts))])\n",
    "print(df_sim.round(2))\n",
    "\n",
    "print(\"\\nTexts:\")\n",
    "for i, text in enumerate(security_texts):\n",
    "    print(f\"T{i}: {text[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Training Data for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security-specific training pairs\n",
    "# Format: (anchor, positive, negative)\n",
    "TRAINING_TRIPLETS = [\n",
    "    # Similar attack types should be close\n",
    "    (\"PowerShell encoded command execution\", \n",
    "     \"Base64 encoded PowerShell payload\",\n",
    "     \"User login from new device\"),\n",
    "    \n",
    "    (\"Failed SSH brute force attempt\",\n",
    "     \"Multiple failed RDP authentication\",\n",
    "     \"Scheduled task created\"),\n",
    "    \n",
    "    (\"Lateral movement via PsExec\",\n",
    "     \"Remote execution using WMI\",\n",
    "     \"File download completed\"),\n",
    "    \n",
    "    (\"Credential dumping from LSASS\",\n",
    "     \"Mimikatz execution detected\",\n",
    "     \"Normal user logout\"),\n",
    "]\n",
    "\n",
    "print(f\"Training triplets: {len(TRAINING_TRIPLETS)}\")\n",
    "print(\"\\nExample triplet:\")\n",
    "print(f\"  Anchor: {TRAINING_TRIPLETS[0][0]}\")\n",
    "print(f\"  Positive: {TRAINING_TRIPLETS[0][1]}\")\n",
    "print(f\"  Negative: {TRAINING_TRIPLETS[0][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning Process (Conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a conceptual example - actual fine-tuning requires more data and compute\n",
    "\n",
    "from sentence_transformers import losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def prepare_training_data(triplets: List[tuple]) -> List[InputExample]:\n",
    "    \"\"\"Convert triplets to training examples.\"\"\"\n",
    "    examples = []\n",
    "    for anchor, positive, negative in triplets:\n",
    "        examples.append(InputExample(texts=[anchor, positive, negative]))\n",
    "    return examples\n",
    "\n",
    "# Prepare data\n",
    "train_examples = prepare_training_data(TRAINING_TRIPLETS)\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.TripletLoss(model=model)\n",
    "\n",
    "print(\"Fine-tuning configuration:\")\n",
    "print(f\"  Training examples: {len(train_examples)}\")\n",
    "print(f\"  Loss function: TripletLoss\")\n",
    "print(f\"  Model: {model.__class__.__name__}\")\n",
    "\n",
    "# NOTE: Actual training would be:\n",
    "# model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "#           epochs=10,\n",
    "#           warmup_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LoRA Fine-Tuning Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA (Low-Rank Adaptation) concept visualization\n",
    "\n",
    "def explain_lora():\n",
    "    \"\"\"\n",
    "    LoRA adds small trainable matrices to frozen base model.\n",
    "    \n",
    "    Original: W (frozen, large matrix)\n",
    "    LoRA: W + BA where B and A are small matrices\n",
    "    \n",
    "    Benefits:\n",
    "    - Much fewer parameters to train\n",
    "    - Can swap adapters for different tasks\n",
    "    - Base model stays frozen (stable)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate parameter counts\n",
    "    base_params = 125_000_000  # 125M parameter model\n",
    "    rank = 8  # LoRA rank\n",
    "    hidden_dim = 768\n",
    "    n_layers = 12\n",
    "    \n",
    "    lora_params = 2 * rank * hidden_dim * n_layers * 2  # A and B matrices, Q and V\n",
    "    \n",
    "    print(\"LoRA Efficiency:\")\n",
    "    print(f\"  Base model parameters: {base_params:,}\")\n",
    "    print(f\"  LoRA parameters: {lora_params:,}\")\n",
    "    print(f\"  Reduction: {lora_params/base_params:.4%}\")\n",
    "\n",
    "explain_lora()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Security-Specific Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security benchmark evaluation\n",
    "\n",
    "SECURITY_BENCHMARK = [\n",
    "    # (query, expected_similar, expected_different)\n",
    "    (\"Credential theft via Mimikatz\", \"LSASS memory dump\", \"User password change\"),\n",
    "    (\"C2 beacon over HTTPS\", \"Encrypted C2 traffic\", \"Normal web browsing\"),\n",
    "    (\"Ransomware encryption detected\", \"Files encrypted with high entropy\", \"Backup job completed\"),\n",
    "]\n",
    "\n",
    "def evaluate_security_model(model, benchmark: List[tuple]) -> Dict:\n",
    "    \"\"\"Evaluate model on security benchmark.\"\"\"\n",
    "    correct = 0\n",
    "    total = len(benchmark)\n",
    "    \n",
    "    for query, similar, different in benchmark:\n",
    "        embeddings = model.encode([query, similar, different])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        sim_similar = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "        sim_different = cosine_similarity([embeddings[0]], [embeddings[2]])[0][0]\n",
    "        \n",
    "        # Check if similar is closer than different\n",
    "        if sim_similar > sim_different:\n",
    "            correct += 1\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": correct / total,\n",
    "        \"correct\": correct,\n",
    "        \"total\": total\n",
    "    }\n",
    "\n",
    "results = evaluate_security_model(model, SECURITY_BENCHMARK)\n",
    "print(f\"Security Benchmark Results:\")\n",
    "print(f\"  Accuracy: {results['accuracy']:.2%}\")\n",
    "print(f\"  Correct: {results['correct']}/{results['total']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model deployment configuration\n",
    "\n",
    "DEPLOYMENT_CONFIG = {\n",
    "    \"model_name\": \"security-embeddings-v1\",\n",
    "    \"base_model\": \"all-MiniLM-L6-v2\",\n",
    "    \"fine_tuning\": {\n",
    "        \"method\": \"triplet_loss\",\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"format\": \"ONNX\",\n",
    "        \"quantization\": \"int8\",\n",
    "        \"max_batch_size\": 64,\n",
    "        \"max_sequence_length\": 256\n",
    "    },\n",
    "    \"monitoring\": {\n",
    "        \"track_latency\": True,\n",
    "        \"track_drift\": True,\n",
    "        \"alert_threshold\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "print(\"Deployment Configuration:\")\n",
    "print(json.dumps(DEPLOYMENT_CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Domain Embeddings**: Security text needs specialized embeddings\n",
    "2. **Triplet Loss**: Train similar items to be close, different items far\n",
    "3. **LoRA**: Efficient fine-tuning with minimal parameters\n",
    "4. **Evaluation**: Use security-specific benchmarks\n",
    "\n",
    "## Next Steps\n",
    "- **Lab 19**: Cloud Security AI\n",
    "- Apply fine-tuned models to your security use cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
