{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 03b: ML vs LLM - When to Use Which?\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab03b_ml_vs_llm.ipynb)\n",
        "\n",
        "Solve the same security problem with both ML and LLM, then compare results.\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand when to use ML vs LLM for security tasks\n",
        "- Implement the same classifier with both approaches\n",
        "- Compare speed, cost, accuracy, and flexibility\n",
        "- Design hybrid systems that use both effectively\n",
        "\n",
        "## The Challenge\n",
        "\n",
        "You're a SOC analyst receiving thousands of log entries. Your task: classify each as **malicious** or **benign**.\n",
        "\n",
        "We'll solve this with **both approaches** and compare!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Install dependencies (Colab only)\n",
        "#@markdown Run this cell to install required packages in Colab\n",
        "\n",
        "%pip install -q scikit-learn numpy pandas anthropic openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(\"âœ… Libraries loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Two Approaches\n",
        "\n",
        "### Approach 1: Traditional ML\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    ML CLASSIFICATION                         â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                             â”‚\n",
        "â”‚   Log Entry                                                 â”‚\n",
        "â”‚       â”‚                                                     â”‚\n",
        "â”‚       â–¼                                                     â”‚\n",
        "â”‚   Feature Extraction                                        â”‚\n",
        "â”‚   â”œâ”€â”€ \"failed\" in text? â†’ 1                                â”‚\n",
        "â”‚   â”œâ”€â”€ \"login\" in text? â†’ 1                                 â”‚\n",
        "â”‚   â”œâ”€â”€ external IP? â†’ 1                                     â”‚\n",
        "â”‚   â””â”€â”€ suspicious keywords? â†’ 3                             â”‚\n",
        "â”‚       â”‚                                                     â”‚\n",
        "â”‚       â–¼                                                     â”‚\n",
        "â”‚   [1, 1, 1, 3] â†’ Model â†’ 0.87 â†’ MALICIOUS                  â”‚\n",
        "â”‚                                                             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Approach 2: LLM Classification\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    LLM CLASSIFICATION                        â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                             â”‚\n",
        "â”‚   Log Entry                                                 â”‚\n",
        "â”‚       â”‚                                                     â”‚\n",
        "â”‚       â–¼                                                     â”‚\n",
        "â”‚   Prompt: \"You are a security analyst. Classify this log   â”‚\n",
        "â”‚   entry as MALICIOUS or BENIGN. Explain your reasoning.    â”‚\n",
        "â”‚                                                             â”‚\n",
        "â”‚   Log: Failed login attempt for user admin from IP          â”‚\n",
        "â”‚   185.143.223.47\"                                           â”‚\n",
        "â”‚       â”‚                                                     â”‚\n",
        "â”‚       â–¼                                                     â”‚\n",
        "â”‚   LLM Response:                                             â”‚\n",
        "â”‚   \"MALICIOUS - Multiple red flags:                         â”‚\n",
        "â”‚    1. Failed login to privileged 'admin' account           â”‚\n",
        "â”‚    2. External IP attempting internal access               â”‚\n",
        "â”‚    3. Pattern consistent with brute force attack\"          â”‚\n",
        "â”‚                                                             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Comparison at a Glance\n",
        "\n",
        "| Factor | ML | LLM | Winner |\n",
        "|--------|-----|-----|--------|\n",
        "| **1,000 predictions** | <1 second | 5-30 minutes* | ML |\n",
        "| **Cost for 10K logs** | ~$0 | ~$5-50* | ML |\n",
        "| **Novel attack pattern** | May miss | Can reason | LLM |\n",
        "| **Explanation for analyst** | \"Feature X high\" | Full context | LLM |\n",
        "| **Works offline** | Yes | No (API) | ML |\n",
        "\n",
        "*LLM times and costs vary by model, provider, and prompt length. Costs have dropped significantly - check current pricing.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Sample Log Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample log entries for classification\n",
        "# In reality, these would come from your SIEM (Splunk, Elastic, etc.) or log aggregator\n",
        "\n",
        "SAMPLE_LOGS = [\n",
        "    # Malicious logs (label = 1)\n",
        "    {\"log\": \"Failed login attempt for user admin from IP 185.143.223.47\", \"label\": 1},\n",
        "    {\"log\": \"PowerShell execution: -enc JABjAGwAaQBlAG4AdA...\", \"label\": 1},\n",
        "    {\"log\": \"Multiple failed SSH attempts from 45.33.32.156\", \"label\": 1},\n",
        "    {\"log\": \"Suspicious process: cmd.exe spawned by WINWORD.EXE\", \"label\": 1},\n",
        "    {\"log\": \"Outbound connection to known C2 IP 91.219.28.103\", \"label\": 1},\n",
        "    {\"log\": \"Registry modification: HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\", \"label\": 1},\n",
        "    {\"log\": \"Data exfiltration detected: 500MB uploaded to external IP\", \"label\": 1},\n",
        "    {\"log\": \"Mimikatz signature detected in memory\", \"label\": 1},\n",
        "    {\"log\": \"Failed login admin from 10.0.0.1 - brute force pattern\", \"label\": 1},\n",
        "    {\"log\": \"Ransomware behavior: mass file encryption detected\", \"label\": 1},\n",
        "    # Benign logs (label = 0)\n",
        "    {\"log\": \"User john.doe logged in successfully from 192.168.1.50\", \"label\": 0},\n",
        "    {\"log\": \"Scheduled task Windows Update ran successfully\", \"label\": 0},\n",
        "    {\"log\": \"File backup completed: 1,234 files processed\", \"label\": 0},\n",
        "    {\"log\": \"User password changed for account mary.smith\", \"label\": 0},\n",
        "    {\"log\": \"Software update installed: Chrome 120.0.6099.109\", \"label\": 0},\n",
        "    {\"log\": \"Print job completed for user finance_dept\", \"label\": 0},\n",
        "    {\"log\": \"VPN connection established for remote_worker01\", \"label\": 0},\n",
        "    {\"log\": \"Email sent from ceo@company.com to board@company.com\", \"label\": 0},\n",
        "    {\"log\": \"Database backup completed successfully\", \"label\": 0},\n",
        "    {\"log\": \"User logged out: session timeout after 30 minutes\", \"label\": 0},\n",
        "]\n",
        "\n",
        "# Shuffle and split the data\n",
        "import random\n",
        "random.seed(42)\n",
        "shuffled = SAMPLE_LOGS.copy()\n",
        "random.shuffle(shuffled)\n",
        "\n",
        "logs = [item[\"log\"] for item in shuffled]\n",
        "labels = [item[\"label\"] for item in shuffled]\n",
        "\n",
        "print(f\"ğŸ“Š Dataset: {len(logs)} log entries\")\n",
        "print(f\"   Malicious: {sum(labels)}\")\n",
        "print(f\"   Benign: {len(labels) - sum(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: ML Classifier\n",
        "\n",
        "Build a traditional ML classifier using feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ML Approach: Feature Engineering + Logistic Regression\n",
        "\n",
        "# Define suspicious keywords that often appear in malicious logs\n",
        "SUSPICIOUS_KEYWORDS = [\n",
        "    \"failed\", \"error\", \"unauthorized\", \"denied\", \"blocked\",\n",
        "    \"malicious\", \"suspicious\", \"attack\", \"exploit\", \"inject\",\n",
        "    \"powershell\", \"cmd.exe\", \"mimikatz\", \"ransomware\", \"c2\",\n",
        "    \"encoded\", \"encrypted\", \"exfiltration\", \"brute\"\n",
        "]\n",
        "\n",
        "def extract_features(log: str) -> List[float]:\n",
        "    \"\"\"\n",
        "    Extract numerical features from a log entry.\n",
        "\n",
        "    This is the key step in ML - converting text to numbers!\n",
        "\n",
        "    Args:\n",
        "        log: Raw log text\n",
        "\n",
        "    Returns:\n",
        "        List of feature values\n",
        "    \"\"\"\n",
        "    log_lower = log.lower()\n",
        "\n",
        "    features = [\n",
        "        # Feature 1: Count of suspicious keywords\n",
        "        sum(1 for kw in SUSPICIOUS_KEYWORDS if kw in log_lower),\n",
        "\n",
        "        # Feature 2: Contains \"failed\" or \"error\"\n",
        "        1 if \"failed\" in log_lower or \"error\" in log_lower else 0,\n",
        "\n",
        "        # Feature 3: Contains IP address pattern\n",
        "        1 if any(c.isdigit() and \".\" in log for c in log) else 0,\n",
        "\n",
        "        # Feature 4: Log length (longer logs often more suspicious)\n",
        "        len(log) / 100,  # Normalize\n",
        "\n",
        "        # Feature 5: Contains \"admin\" or \"root\"\n",
        "        1 if \"admin\" in log_lower or \"root\" in log_lower else 0,\n",
        "\n",
        "        # Feature 6: Contains encoded/encrypted indicators\n",
        "        1 if \"enc\" in log_lower or \"base64\" in log_lower else 0,\n",
        "    ]\n",
        "\n",
        "    return features\n",
        "\n",
        "# Test feature extraction\n",
        "print(\"Feature extraction examples:\")\n",
        "print(f\"  Malicious log: {extract_features(SAMPLE_LOGS[0]['log'])}\")\n",
        "print(f\"  Benign log: {extract_features(SAMPLE_LOGS[10]['log'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the ML classifier\n",
        "\n",
        "# Extract features for all logs\n",
        "X = np.array([extract_features(log) for log in logs])\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data (use same indices for fair comparison later!)\n",
        "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
        "    X, y, range(len(logs)), test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "ml_model = LogisticRegression(random_state=42)\n",
        "ml_model.fit(X_train, y_train)\n",
        "ml_train_time = time.time() - start_time\n",
        "\n",
        "# Make predictions\n",
        "start_time = time.time()\n",
        "ml_predictions = ml_model.predict(X_test)\n",
        "ml_predict_time = time.time() - start_time\n",
        "\n",
        "# Evaluate\n",
        "ml_accuracy = accuracy_score(y_test, ml_predictions)\n",
        "ml_precision = precision_score(y_test, ml_predictions, zero_division=0)\n",
        "ml_recall = recall_score(y_test, ml_predictions, zero_division=0)\n",
        "\n",
        "print(\"ğŸ“Š ML CLASSIFIER RESULTS\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Training time:    {ml_train_time*1000:.2f}ms\")\n",
        "print(f\"Prediction time:  {ml_predict_time*1000:.2f}ms ({len(y_test)} samples)\")\n",
        "print(f\"Accuracy:         {ml_accuracy:.1%}\")\n",
        "print(f\"Precision:        {ml_precision:.1%}\")\n",
        "print(f\"Recall:           {ml_recall:.1%}\")\n",
        "print(f\"Cost:             $0.00\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: LLM Classifier\n",
        "\n",
        "Now let's use an LLM to classify the same logs.\n",
        "\n",
        "> **Note**: This requires an API key. If you don't have one, you can still read the code to understand the approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM Classification approach\n",
        "# This demonstrates the pattern - you'll need an API key to run\n",
        "\n",
        "CLASSIFICATION_PROMPT = \"\"\"You are a security analyst. Classify this log entry.\n",
        "\n",
        "Log: {log_entry}\n",
        "\n",
        "Respond with EXACTLY one word: MALICIOUS or BENIGN\n",
        "\"\"\"\n",
        "\n",
        "def llm_classify_simulated(log: str) -> str:\n",
        "    \"\"\"\n",
        "    Simulated LLM classification for demo purposes.\n",
        "\n",
        "    In production, this would call an actual LLM API.\n",
        "    This simulation mimics LLM reasoning based on keywords.\n",
        "\n",
        "    Args:\n",
        "        log: Log entry to classify\n",
        "\n",
        "    Returns:\n",
        "        \"MALICIOUS\" or \"BENIGN\"\n",
        "    \"\"\"\n",
        "    # Simulate LLM processing time (real API takes 500-2000ms)\n",
        "    time.sleep(0.1)  # Reduced for demo\n",
        "\n",
        "    # Simple rule-based simulation of LLM reasoning\n",
        "    # Real LLM would understand context much better!\n",
        "    malicious_indicators = [\n",
        "        \"failed\", \"attack\", \"malicious\", \"suspicious\",\n",
        "        \"c2\", \"mimikatz\", \"ransomware\", \"exfiltration\",\n",
        "        \"powershell -enc\", \"spawned by\"\n",
        "    ]\n",
        "\n",
        "    log_lower = log.lower()\n",
        "    if any(ind in log_lower for ind in malicious_indicators):\n",
        "        return \"MALICIOUS\"\n",
        "    return \"BENIGN\"\n",
        "\n",
        "# Test on same test set\n",
        "print(\"ğŸ¤– LLM CLASSIFIER (Simulated)\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Use same test indices for fair comparison!\n",
        "test_logs = [logs[i] for i in test_idx]\n",
        "\n",
        "start_time = time.time()\n",
        "llm_predictions = []\n",
        "for log in test_logs:\n",
        "    pred = llm_classify_simulated(log)\n",
        "    llm_predictions.append(1 if pred == \"MALICIOUS\" else 0)\n",
        "llm_predict_time = time.time() - start_time\n",
        "\n",
        "# Evaluate\n",
        "llm_accuracy = accuracy_score(y_test, llm_predictions)\n",
        "llm_precision = precision_score(y_test, llm_predictions, zero_division=0)\n",
        "llm_recall = recall_score(y_test, llm_predictions, zero_division=0)\n",
        "\n",
        "print(f\"Prediction time:  {llm_predict_time*1000:.2f}ms ({len(y_test)} samples)\")\n",
        "print(f\"Accuracy:         {llm_accuracy:.1%}\")\n",
        "print(f\"Precision:        {llm_precision:.1%}\")\n",
        "print(f\"Recall:           {llm_recall:.1%}\")\n",
        "print(f\"Est. Cost:        ~${len(y_test) * 0.001:.2f} (at $0.001/call)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: The Hybrid Pattern\n",
        "\n",
        "The best approach: **Use both!** ML handles bulk filtering, LLM handles uncertain cases.\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    HYBRID ARCHITECTURE                       â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                             â”‚\n",
        "â”‚   10,000 Log Entries                                        â”‚\n",
        "â”‚           â”‚                                                 â”‚\n",
        "â”‚           â–¼                                                 â”‚\n",
        "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚\n",
        "â”‚   â”‚   ML FAST FILTER  â”‚  â† Process ALL logs                â”‚\n",
        "â”‚   â”‚   (1 second)      â”‚     Cost: ~$0                      â”‚\n",
        "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚\n",
        "â”‚             â”‚                                               â”‚\n",
        "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚\n",
        "â”‚     â”‚               â”‚                                       â”‚\n",
        "â”‚     â–¼               â–¼                                       â”‚\n",
        "â”‚  BENIGN (9,500)  SUSPICIOUS (500)                          â”‚\n",
        "â”‚  Auto-close      â”‚                                          â”‚\n",
        "â”‚                  â–¼                                          â”‚\n",
        "â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚\n",
        "â”‚          â”‚   LLM ANALYSIS    â”‚  â† Only suspicious          â”‚\n",
        "â”‚          â”‚   (5 minutes)     â”‚     Cost: ~$5               â”‚\n",
        "â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚\n",
        "â”‚                    â”‚                                        â”‚\n",
        "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                               â”‚\n",
        "â”‚            â”‚               â”‚                                â”‚\n",
        "â”‚            â–¼               â–¼                                â”‚\n",
        "â”‚     False Positive    TRUE THREAT                           â”‚\n",
        "â”‚     Auto-close        â†’ Human Review                        â”‚\n",
        "â”‚                                                             â”‚\n",
        "â”‚   TOTAL: 10K logs in ~5 min, cost ~$5                      â”‚\n",
        "â”‚   vs LLM-only: 10K logs in ~3 hours, cost ~$100            â”‚\n",
        "â”‚                                                             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid approach: ML filter + LLM for uncertain cases\n",
        "\n",
        "def hybrid_classify(log: str, model, threshold_low=0.3, threshold_high=0.7):\n",
        "    \"\"\"\n",
        "    Hybrid classifier: ML for confident cases, LLM for uncertain ones.\n",
        "\n",
        "    Args:\n",
        "        log: Log entry to classify\n",
        "        model: Trained ML model\n",
        "        threshold_low: Below this = definitely benign\n",
        "        threshold_high: Above this = definitely malicious\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (prediction, used_llm)\n",
        "    \"\"\"\n",
        "    # Step 1: Get ML probability\n",
        "    features = np.array([extract_features(log)])\n",
        "    probability = model.predict_proba(features)[0][1]  # P(malicious)\n",
        "\n",
        "    # Step 2: Decide if confident enough\n",
        "    if probability < threshold_low:\n",
        "        return 0, False  # Definitely benign, ML only\n",
        "    elif probability > threshold_high:\n",
        "        return 1, False  # Definitely malicious, ML only\n",
        "    else:\n",
        "        # Uncertain - use LLM\n",
        "        llm_result = llm_classify_simulated(log)\n",
        "        return 1 if llm_result == \"MALICIOUS\" else 0, True\n",
        "\n",
        "# Test hybrid approach\n",
        "print(\"ğŸ”€ HYBRID CLASSIFIER\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "start_time = time.time()\n",
        "hybrid_predictions = []\n",
        "llm_calls = 0\n",
        "\n",
        "for log in test_logs:\n",
        "    pred, used_llm = hybrid_classify(log, ml_model)\n",
        "    hybrid_predictions.append(pred)\n",
        "    if used_llm:\n",
        "        llm_calls += 1\n",
        "\n",
        "hybrid_predict_time = time.time() - start_time\n",
        "\n",
        "# Evaluate\n",
        "hybrid_accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "hybrid_precision = precision_score(y_test, hybrid_predictions, zero_division=0)\n",
        "hybrid_recall = recall_score(y_test, hybrid_predictions, zero_division=0)\n",
        "\n",
        "print(f\"Prediction time:  {hybrid_predict_time*1000:.2f}ms\")\n",
        "print(f\"LLM calls:        {llm_calls}/{len(y_test)} ({llm_calls/len(y_test)*100:.0f}%)\")\n",
        "print(f\"Accuracy:         {hybrid_accuracy:.1%}\")\n",
        "print(f\"Precision:        {hybrid_precision:.1%}\")\n",
        "print(f\"Recall:           {hybrid_recall:.1%}\")\n",
        "print(f\"Est. Cost:        ~${llm_calls * 0.001:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‰ Summary & Decision Framework\n",
        "\n",
        "### Results Comparison\n",
        "\n",
        "| Approach | Speed | Cost | Accuracy | Best For |\n",
        "|----------|-------|------|----------|----------|\n",
        "| **ML Only** | Fastest | Free | Good | High volume, known patterns |\n",
        "| **LLM Only** | Slowest | Highest | Best | Novel patterns, explanations |\n",
        "| **Hybrid** | Fast | Low | Great | Best of both worlds |\n",
        "\n",
        "### When to Use What\n",
        "\n",
        "```\n",
        "START: What's your constraint?\n",
        "â”‚\n",
        "â”œâ”€â–º Speed/Volume critical (>100/sec)\n",
        "â”‚   â””â”€â–º Use ML\n",
        "â”‚\n",
        "â”œâ”€â–º Cost critical (<$0.01/prediction)\n",
        "â”‚   â””â”€â–º Use ML\n",
        "â”‚\n",
        "â”œâ”€â–º Need natural language explanation\n",
        "â”‚   â””â”€â–º Use LLM (or Hybrid with LLM for uncertain)\n",
        "â”‚\n",
        "â”œâ”€â–º Handling novel/unknown patterns\n",
        "â”‚   â””â”€â–º Use LLM (or Hybrid)\n",
        "â”‚\n",
        "â”œâ”€â–º Must work offline/air-gapped\n",
        "â”‚   â””â”€â–º Use ML\n",
        "â”‚\n",
        "â””â”€â–º Want best of both worlds\n",
        "    â””â”€â–º Use Hybrid (ML filter â†’ LLM verify)\n",
        "```\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **ML excels at** high-volume, known-pattern, low-cost scenarios\n",
        "2. **LLM excels at** reasoning, flexibility, and explanation\n",
        "3. **Hybrid is often best** - ML handles bulk, LLM handles edge cases\n",
        "4. **Know your constraints** - speed, cost, accuracy, explainability\n",
        "5. **Measure both** - don't assume, test on your data\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- **Lab 04**: Deep dive into LLM prompt engineering\n",
        "- **Lab 05**: Build agents that combine ML + LLM\n",
        "- **Lab 09**: Production hybrid detection pipeline"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
