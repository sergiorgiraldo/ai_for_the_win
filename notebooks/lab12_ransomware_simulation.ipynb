{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 12: Ransomware Simulation (Purple Team)\n",
    "\n",
    "Build safe simulation tools for testing ransomware defenses.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab12_ransomware_simulation.ipynb)\n",
    "\n",
    "**ETHICAL NOTE**: This lab is for authorized testing only. All simulations are safe and non-destructive.\n",
    "\n",
    "## Learning Objectives\n",
    "- Adversary emulation planning\n",
    "- Safe simulation techniques\n",
    "- Detection validation\n",
    "- Gap analysis and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Attack Scenario Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RansomwareFamily(Enum):\n",
    "    LOCKBIT = \"lockbit\"\n",
    "    BLACKCAT = \"blackcat\"\n",
    "    CONTI = \"conti\"\n",
    "\n",
    "@dataclass\n",
    "class AttackScenario:\n",
    "    \"\"\"Ransomware attack scenario.\"\"\"\n",
    "    family: RansomwareFamily\n",
    "    name: str\n",
    "    description: str\n",
    "    mitre_techniques: List[str]\n",
    "    detection_opportunities: List[str]\n",
    "\n",
    "# Define scenarios\n",
    "SCENARIOS = {\n",
    "    RansomwareFamily.LOCKBIT: AttackScenario(\n",
    "        family=RansomwareFamily.LOCKBIT,\n",
    "        name=\"LockBit 3.0 Simulation\",\n",
    "        description=\"Fast-encrypting RaaS with double extortion\",\n",
    "        mitre_techniques=[\"T1486\", \"T1490\", \"T1059.001\", \"T1567\"],\n",
    "        detection_opportunities=[\n",
    "            \"Shadow copy deletion commands\",\n",
    "            \"Mass file extension changes\",\n",
    "            \"Ransom note creation\",\n",
    "            \"Large outbound transfers\"\n",
    "        ]\n",
    "    ),\n",
    "    RansomwareFamily.BLACKCAT: AttackScenario(\n",
    "        family=RansomwareFamily.BLACKCAT,\n",
    "        name=\"BlackCat/ALPHV Simulation\",\n",
    "        description=\"Rust-based cross-platform ransomware\",\n",
    "        mitre_techniques=[\"T1486\", \"T1490\", \"T1048\", \"T1070\"],\n",
    "        detection_opportunities=[\n",
    "            \"Unusual Rust binary execution\",\n",
    "            \"Config file creation\",\n",
    "            \"Service stop commands\",\n",
    "            \"ESXi targeting behavior\"\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Available Scenarios:\")\n",
    "for family, scenario in SCENARIOS.items():\n",
    "    print(f\"\\n{scenario.name}\")\n",
    "    print(f\"  Description: {scenario.description}\")\n",
    "    print(f\"  Techniques: {scenario.mitre_techniques}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Safe Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    \"\"\"Safe simulation configuration.\"\"\"\n",
    "    target_directory: str\n",
    "    file_extensions: List[str] = field(default_factory=lambda: [\".txt\", \".docx\"])\n",
    "    simulate_encryption: bool = True\n",
    "    create_ransom_note: bool = True\n",
    "    cleanup_after: bool = True\n",
    "\n",
    "class SafeRansomwareSimulator:\n",
    "    \"\"\"\n",
    "    Safe ransomware behavior simulator.\n",
    "    \n",
    "    SAFETY: Only operates in temp directories,\n",
    "    no actual encryption, full audit logging.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: SimulationConfig):\n",
    "        self.config = config\n",
    "        self.audit_log = []\n",
    "        self.created_files = []\n",
    "        self._validate_safe_directory()\n",
    "    \n",
    "    def _validate_safe_directory(self):\n",
    "        \"\"\"Ensure we're in a safe directory.\"\"\"\n",
    "        path = Path(self.config.target_directory).resolve()\n",
    "        temp_dir = Path(tempfile.gettempdir())\n",
    "        \n",
    "        if not str(path).startswith(str(temp_dir)):\n",
    "            raise ValueError(f\"Target must be in temp directory: {temp_dir}\")\n",
    "        \n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def _log(self, action: str, details: Dict):\n",
    "        self.audit_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": action,\n",
    "            **details\n",
    "        })\n",
    "    \n",
    "    def setup_test_files(self, num_files: int = 5) -> List[str]:\n",
    "        \"\"\"Create test files for simulation.\"\"\"\n",
    "        files = []\n",
    "        target = Path(self.config.target_directory)\n",
    "        \n",
    "        for i in range(num_files):\n",
    "            for ext in self.config.file_extensions:\n",
    "                filepath = target / f\"test_file_{i}{ext}\"\n",
    "                filepath.write_text(f\"Test content for {filepath.name}\")\n",
    "                files.append(str(filepath))\n",
    "                self.created_files.append(str(filepath))\n",
    "        \n",
    "        self._log(\"SETUP\", {\"files_created\": len(files)})\n",
    "        return files\n",
    "    \n",
    "    def simulate_encryption(self, files: List[str]) -> Dict:\n",
    "        \"\"\"Simulate encryption (just renaming, NOT actual encryption).\"\"\"\n",
    "        if not self.config.simulate_encryption:\n",
    "            return {\"simulated\": False}\n",
    "        \n",
    "        affected = 0\n",
    "        for filepath in files:\n",
    "            original = Path(filepath)\n",
    "            if original.exists():\n",
    "                new_path = str(original) + \".encrypted\"\n",
    "                shutil.move(str(original), new_path)\n",
    "                affected += 1\n",
    "                self._log(\"ENCRYPT_SIM\", {\"file\": str(original)})\n",
    "        \n",
    "        return {\"simulated\": True, \"files_affected\": affected}\n",
    "    \n",
    "    def create_ransom_note(self) -> str:\n",
    "        \"\"\"Create simulated ransom note.\"\"\"\n",
    "        if not self.config.create_ransom_note:\n",
    "            return \"\"\n",
    "        \n",
    "        note = f\"\"\"\n",
    "=== SIMULATION RANSOM NOTE ===\n",
    "This is a SIMULATED ransom note for purple team testing.\n",
    "No actual ransomware was deployed.\n",
    "\n",
    "Test ID: PURPLE-TEAM-{datetime.now().strftime('%Y%m%d-%H%M%S')}\n",
    "=== END SIMULATION ===\n",
    "\"\"\"\n",
    "        \n",
    "        note_path = Path(self.config.target_directory) / \"README_RESTORE_FILES.txt\"\n",
    "        note_path.write_text(note)\n",
    "        self.created_files.append(str(note_path))\n",
    "        self._log(\"RANSOM_NOTE\", {\"path\": str(note_path)})\n",
    "        \n",
    "        return str(note_path)\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up all created files.\"\"\"\n",
    "        if not self.config.cleanup_after:\n",
    "            return\n",
    "        \n",
    "        for filepath in self.created_files:\n",
    "            path = Path(filepath)\n",
    "            if path.exists():\n",
    "                path.unlink()\n",
    "            # Also check for .encrypted version\n",
    "            enc_path = Path(filepath + \".encrypted\")\n",
    "            if enc_path.exists():\n",
    "                enc_path.unlink()\n",
    "        \n",
    "        self._log(\"CLEANUP\", {\"files_removed\": len(self.created_files)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    config = SimulationConfig(\n",
    "        target_directory=tmpdir,\n",
    "        simulate_encryption=True,\n",
    "        create_ransom_note=True,\n",
    "        cleanup_after=True\n",
    "    )\n",
    "    \n",
    "    simulator = SafeRansomwareSimulator(config)\n",
    "    \n",
    "    # Run simulation\n",
    "    print(\"Running Safe Simulation:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    files = simulator.setup_test_files(num_files=3)\n",
    "    print(f\"1. Created {len(files)} test files\")\n",
    "    \n",
    "    result = simulator.simulate_encryption(files)\n",
    "    print(f\"2. Simulated encryption of {result['files_affected']} files\")\n",
    "    \n",
    "    note = simulator.create_ransom_note()\n",
    "    print(f\"3. Created ransom note: {Path(note).name}\")\n",
    "    \n",
    "    # Show audit log\n",
    "    print(f\"\\nAudit Log: {len(simulator.audit_log)} entries\")\n",
    "    \n",
    "    # Cleanup\n",
    "    simulator.cleanup()\n",
    "    print(\"4. Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Detection Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionStatus(Enum):\n",
    "    DETECTED = \"detected\"\n",
    "    MISSED = \"missed\"\n",
    "    PENDING = \"pending\"\n",
    "\n",
    "@dataclass\n",
    "class DetectionTest:\n",
    "    name: str\n",
    "    technique_id: str\n",
    "    description: str\n",
    "    status: DetectionStatus = DetectionStatus.PENDING\n",
    "\n",
    "class DetectionValidator:\n",
    "    \"\"\"Validate detection coverage.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tests = [\n",
    "            DetectionTest(\"Shadow Copy Deletion\", \"T1490\", \"vssadmin delete shadows\"),\n",
    "            DetectionTest(\"Mass File Modification\", \"T1486\", \"Rapid file extension changes\"),\n",
    "            DetectionTest(\"Ransom Note Creation\", \"T1486\", \"README/DECRYPT file creation\"),\n",
    "            DetectionTest(\"Service Termination\", \"T1489\", \"Backup service stops\")\n",
    "        ]\n",
    "    \n",
    "    def generate_gap_analysis(self) -> Dict:\n",
    "        detected = sum(1 for t in self.tests if t.status == DetectionStatus.DETECTED)\n",
    "        missed = sum(1 for t in self.tests if t.status == DetectionStatus.MISSED)\n",
    "        \n",
    "        return {\n",
    "            \"total_tests\": len(self.tests),\n",
    "            \"detected\": detected,\n",
    "            \"missed\": missed,\n",
    "            \"coverage\": f\"{(detected/len(self.tests))*100:.0f}%\" if self.tests else \"0%\",\n",
    "            \"gaps\": [t.name for t in self.tests if t.status == DetectionStatus.MISSED]\n",
    "        }\n",
    "\n",
    "# Example validation\n",
    "validator = DetectionValidator()\n",
    "\n",
    "# Simulate test results\n",
    "validator.tests[0].status = DetectionStatus.DETECTED\n",
    "validator.tests[1].status = DetectionStatus.DETECTED\n",
    "validator.tests[2].status = DetectionStatus.MISSED\n",
    "validator.tests[3].status = DetectionStatus.MISSED\n",
    "\n",
    "analysis = validator.generate_gap_analysis()\n",
    "\n",
    "print(\"Detection Gap Analysis:\")\n",
    "print(f\"  Coverage: {analysis['coverage']}\")\n",
    "print(f\"  Detected: {analysis['detected']}/{analysis['total_tests']}\")\n",
    "print(f\"  Gaps: {analysis['gaps']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Exercise Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exercise_report(scenario: AttackScenario, gap_analysis: Dict) -> str:\n",
    "    \"\"\"Generate purple team exercise report.\"\"\"\n",
    "    return f\"\"\"\n",
    "# Purple Team Exercise Report\n",
    "\n",
    "## Scenario\n",
    "- **Name**: {scenario.name}\n",
    "- **Family**: {scenario.family.value}\n",
    "- **Description**: {scenario.description}\n",
    "\n",
    "## MITRE ATT&CK Techniques Tested\n",
    "{chr(10).join(f'- {t}' for t in scenario.mitre_techniques)}\n",
    "\n",
    "## Detection Coverage\n",
    "- **Overall Coverage**: {gap_analysis['coverage']}\n",
    "- **Tests Detected**: {gap_analysis['detected']}\n",
    "- **Tests Missed**: {gap_analysis['missed']}\n",
    "\n",
    "## Detection Gaps\n",
    "{chr(10).join(f'- {g}' for g in gap_analysis['gaps']) or 'None - full coverage!'}\n",
    "\n",
    "## Recommendations\n",
    "1. Implement missing detections for identified gaps\n",
    "2. Tune existing rules to reduce false negatives\n",
    "3. Re-run exercise after remediation\n",
    "4. Document detection playbooks\n",
    "\n",
    "---\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# Generate report\n",
    "scenario = SCENARIOS[RansomwareFamily.LOCKBIT]\n",
    "report = generate_exercise_report(scenario, analysis)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We built a purple team ransomware simulation framework:\n",
    "\n",
    "1. **Scenario Generation** - Model ransomware families\n",
    "2. **Safe Simulation** - Non-destructive behavior emulation\n",
    "3. **Detection Validation** - Test security controls\n",
    "4. **Gap Analysis** - Identify missing coverage\n",
    "\n",
    "### Safety Features:\n",
    "- Only operates in temp directories\n",
    "- No actual encryption (just renaming)\n",
    "- Full audit logging\n",
    "- Automatic cleanup\n",
    "\n",
    "### Next Steps:\n",
    "1. Integrate with detection systems for automated validation\n",
    "2. Add more ransomware family profiles\n",
    "3. Create scheduled exercise automation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
