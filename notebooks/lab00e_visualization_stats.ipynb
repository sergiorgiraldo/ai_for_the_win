{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Lab 00e: Visualization & Statistics for Security\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab00e_visualization_stats.ipynb)\n",
        "\n",
        "Master interactive data visualization and statistical analysis for security data.\n",
        "\n",
        "## Learning Objectives\n",
        "- Calculate baseline statistics for security metrics\n",
        "- Create interactive visualizations with Plotly\n",
        "- Build multi-panel security dashboards\n",
        "- Analyze time series and distributions\n",
        "- Apply statistical methods for anomaly context\n",
        "\n",
        "## Why This Matters\n",
        "\n",
        "| Challenge | Visualization Solution |\n",
        "|-----------|------------------------|\n",
        "| Too much data | Aggregation & filtering |\n",
        "| Hidden patterns | Time series & correlation |\n",
        "| Outlier detection | Distribution plots & z-scores |\n",
        "| Stakeholder reporting | Interactive dashboards |\n",
        "\n",
        "**No API keys required!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (uncomment for Colab)\n",
        "# !pip install plotly pandas numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy import stats\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# Plotly template for consistent styling\n",
        "PLOTLY_TEMPLATE = \"plotly_white\"\n",
        "\n",
        "# Security-focused color scheme\n",
        "COLORS = {\n",
        "    \"primary\": \"#2E86AB\",\n",
        "    \"secondary\": \"#A23B72\",\n",
        "    \"success\": \"#2ECC71\",\n",
        "    \"warning\": \"#F39C12\",\n",
        "    \"danger\": \"#E74C3C\",\n",
        "    \"info\": \"#3498DB\",\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üìä Plotly version: {px.__version__ if hasattr(px, '__version__') else 'installed'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## 1. Generate Sample Security Data\n",
        "\n",
        "We'll create realistic security event data including:\n",
        "- Authentication logs with success/failure\n",
        "- Network traffic with anomalies\n",
        "- Threat scores for IOCs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate security event data\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Authentication events\n",
        "n_events = 200\n",
        "event_types = [\"login\", \"logout\", \"file_access\", \"privilege_escalation\", \"network_scan\"]\n",
        "severities = [\"info\", \"warning\", \"critical\"]\n",
        "users = [\"alice\", \"bob\", \"charlie\", \"admin\", \"service_account\", \"unknown\"]\n",
        "ips = [f\"192.168.1.{i}\" for i in range(1, 20)] + [\"10.0.0.50\", \"10.0.0.51\", \"203.0.113.5\"]\n",
        "\n",
        "events = []\n",
        "base_time = datetime(2024, 1, 15, 0, 0, 0)\n",
        "\n",
        "for i in range(n_events):\n",
        "    # Create realistic attack pattern: more failures at certain times\n",
        "    hour = (i * 7) % 24\n",
        "    is_attack_window = 8 <= hour <= 10  # Attack between 8-10 AM\n",
        "\n",
        "    if is_attack_window and random.random() < 0.4:\n",
        "        event_type = random.choice([\"login\", \"privilege_escalation\", \"network_scan\"])\n",
        "        severity = random.choice([\"warning\", \"critical\"])\n",
        "        success = random.random() < 0.2  # Mostly failures during attack\n",
        "        source_ip = random.choice([\"10.0.0.50\", \"10.0.0.51\", \"203.0.113.5\"])\n",
        "        user = random.choice([\"admin\", \"unknown\"])\n",
        "        response_ms = random.randint(100, 500)  # Slow during attack\n",
        "    else:\n",
        "        event_type = random.choice(event_types)\n",
        "        severity = \"info\" if random.random() < 0.8 else \"warning\"\n",
        "        success = random.random() < 0.95  # Normal success rate\n",
        "        source_ip = random.choice(ips[:18])  # Internal IPs\n",
        "        user = random.choice(users[:4])\n",
        "        response_ms = random.randint(10, 80)\n",
        "\n",
        "    events.append({\n",
        "        \"timestamp\": base_time + timedelta(minutes=i*7),\n",
        "        \"event_type\": event_type,\n",
        "        \"severity\": severity,\n",
        "        \"source_ip\": source_ip,\n",
        "        \"user\": user,\n",
        "        \"success\": success,\n",
        "        \"response_ms\": response_ms,\n",
        "    })\n",
        "\n",
        "events_df = pd.DataFrame(events)\n",
        "\n",
        "print(f\"üìã Generated {len(events_df)} security events\")\n",
        "print(f\"\\nEvent types: {events_df['event_type'].value_counts().to_dict()}\")\n",
        "print(f\"Severity breakdown: {events_df['severity'].value_counts().to_dict()}\")\n",
        "events_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate hourly traffic data with anomaly\n",
        "traffic_data = []\n",
        "for hour in range(24):\n",
        "    # Normal traffic pattern (business hours peak)\n",
        "    if 6 <= hour <= 18:\n",
        "        base_requests = 400 + 300 * np.sin((hour - 6) * np.pi / 12)\n",
        "    else:\n",
        "        base_requests = 100 + 50 * np.random.random()\n",
        "\n",
        "    # Inject anomaly at hour 14 (DDoS simulation)\n",
        "    if hour == 14:\n",
        "        base_requests = 3500  # Massive spike\n",
        "\n",
        "    requests = int(base_requests + np.random.normal(0, 30))\n",
        "    bytes_in = requests * random.randint(350, 450)\n",
        "    bytes_out = requests * random.randint(80, 120)\n",
        "    errors = max(0, int(requests * 0.01 + np.random.normal(0, 2)))\n",
        "\n",
        "    # More errors during anomaly\n",
        "    if hour == 14:\n",
        "        errors = 150\n",
        "\n",
        "    traffic_data.append({\n",
        "        \"hour\": hour,\n",
        "        \"requests\": requests,\n",
        "        \"bytes_in\": bytes_in,\n",
        "        \"bytes_out\": bytes_out,\n",
        "        \"errors\": errors,\n",
        "    })\n",
        "\n",
        "traffic_df = pd.DataFrame(traffic_data)\n",
        "\n",
        "print(\"üìä Traffic Statistics:\")\n",
        "print(traffic_df.describe().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate threat scores (mix of benign and malicious)\n",
        "n_scores = 100\n",
        "\n",
        "# Most are low threat (benign)\n",
        "benign_scores = np.random.beta(2, 8, int(n_scores * 0.7)) * 0.4\n",
        "# Some medium threat\n",
        "medium_scores = np.random.uniform(0.3, 0.7, int(n_scores * 0.15))\n",
        "# Few high threat (malicious)\n",
        "malicious_scores = np.random.beta(8, 2, int(n_scores * 0.15)) * 0.3 + 0.7\n",
        "\n",
        "threat_scores = np.concatenate([benign_scores, medium_scores, malicious_scores])\n",
        "np.random.shuffle(threat_scores)\n",
        "\n",
        "print(f\"üéØ Generated {len(threat_scores)} threat scores\")\n",
        "print(f\"   Low threat (< 0.3): {(threat_scores < 0.3).sum()}\")\n",
        "print(f\"   Medium threat (0.3-0.7): {((threat_scores >= 0.3) & (threat_scores < 0.7)).sum()}\")\n",
        "print(f\"   High threat (>= 0.7): {(threat_scores >= 0.7).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## 2. Statistical Analysis for Security\n",
        "\n",
        "Key statistics help establish baselines and detect anomalies:\n",
        "\n",
        "| Statistic | Formula | Security Use |\n",
        "|-----------|---------|---------------|\n",
        "| Mean | Œ£x/n | Average baseline |\n",
        "| Median | Middle value | Robust to outliers |\n",
        "| Std Dev | ‚àö(Œ£(x-Œº)¬≤/n) | Variability measure |\n",
        "| Z-Score | (x-Œº)/œÉ | Anomaly magnitude |\n",
        "| Percentile | P95, P99 | SLA thresholds |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_baseline_stats(values):\n",
        "    \"\"\"Calculate baseline statistics for security metrics.\"\"\"\n",
        "    arr = np.array(values)\n",
        "    return {\n",
        "        \"mean\": float(np.mean(arr)),\n",
        "        \"median\": float(np.median(arr)),\n",
        "        \"std\": float(np.std(arr)),\n",
        "        \"min\": float(np.min(arr)),\n",
        "        \"max\": float(np.max(arr)),\n",
        "        \"p95\": float(np.percentile(arr, 95)),\n",
        "        \"p99\": float(np.percentile(arr, 99)),\n",
        "    }\n",
        "\n",
        "# Analyze traffic baseline\n",
        "requests = traffic_df[\"requests\"].tolist()\n",
        "baseline = calculate_baseline_stats(requests)\n",
        "\n",
        "print(\"üìä Traffic Baseline Statistics\")\n",
        "print(\"=\" * 40)\n",
        "for key, value in baseline.items():\n",
        "    print(f\"  {key:>8}: {value:>10.2f}\")\n",
        "\n",
        "print(f\"\\nüí° Insight: Traffic above {baseline['p95']:.0f} requests/hour is unusual (top 5%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Z-Score analysis for anomaly detection\n",
        "z_scores = stats.zscore(traffic_df[\"requests\"])\n",
        "traffic_df[\"z_score\"] = z_scores\n",
        "traffic_df[\"is_anomaly\"] = abs(z_scores) > 2\n",
        "\n",
        "print(\"üîç Z-Score Anomaly Detection\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Z-score thresholds:\")\n",
        "print(\"  |z| > 2: Unusual (95% confidence)\")\n",
        "print(\"  |z| > 3: Extreme outlier (99.7% confidence)\")\n",
        "\n",
        "anomalies = traffic_df[traffic_df[\"is_anomaly\"]]\n",
        "print(f\"\\n‚ö†Ô∏è  Anomalies detected: {len(anomalies)}\")\n",
        "\n",
        "for _, row in anomalies.iterrows():\n",
        "    severity = \"üî¥ EXTREME\" if abs(row[\"z_score\"]) > 3 else \"üü° UNUSUAL\"\n",
        "    print(f\"  Hour {row['hour']:2d}: {row['requests']:,} requests (z={row['z_score']:.2f}) {severity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "## 3. Distribution Visualization\n",
        "\n",
        "Understanding data distributions helps identify:\n",
        "- Normal vs abnormal patterns\n",
        "- Outliers and anomalies\n",
        "- Class imbalance in threat data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Threat score distribution with categorization\n",
        "threat_df = pd.DataFrame({\"score\": threat_scores})\n",
        "threat_df[\"threat_level\"] = pd.cut(\n",
        "    threat_df[\"score\"],\n",
        "    bins=[0, 0.3, 0.7, 1.0],\n",
        "    labels=[\"Low\", \"Medium\", \"High\"],\n",
        "    include_lowest=True,\n",
        ")\n",
        "\n",
        "# Calculate statistics\n",
        "mean_score = np.mean(threat_scores)\n",
        "median_score = np.median(threat_scores)\n",
        "\n",
        "fig = px.histogram(\n",
        "    threat_df,\n",
        "    x=\"score\",\n",
        "    color=\"threat_level\",\n",
        "    nbins=25,\n",
        "    title=\"üéØ Threat Score Distribution with Risk Categorization\",\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    color_discrete_map={\n",
        "        \"Low\": COLORS[\"success\"],\n",
        "        \"Medium\": COLORS[\"warning\"],\n",
        "        \"High\": COLORS[\"danger\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Add statistical reference lines\n",
        "fig.add_vline(x=mean_score, line_dash=\"dash\", line_color=COLORS[\"primary\"],\n",
        "              annotation_text=f\"Mean: {mean_score:.2f}\", annotation_position=\"top\")\n",
        "fig.add_vline(x=median_score, line_dash=\"dot\", line_color=COLORS[\"secondary\"],\n",
        "              annotation_text=f\"Median: {median_score:.2f}\", annotation_position=\"bottom\")\n",
        "\n",
        "# Add threshold lines\n",
        "fig.add_vline(x=0.3, line_dash=\"solid\", line_color=\"gray\", line_width=1)\n",
        "fig.add_vline(x=0.7, line_dash=\"solid\", line_color=\"gray\", line_width=1)\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Threat Score (0-1)\",\n",
        "    yaxis_title=\"Count\",\n",
        "    legend_title=\"Risk Level\",\n",
        "    height=450,\n",
        "    bargap=0.1,\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nüìä Distribution Insights:\")\n",
        "print(f\"   Skewness: {stats.skew(threat_scores):.2f} (positive = right-skewed, many low values)\")\n",
        "print(f\"   Kurtosis: {stats.kurtosis(threat_scores):.2f} (high = heavy tails, more outliers)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plot: Response time by event type\n",
        "fig = px.box(\n",
        "    events_df,\n",
        "    x=\"event_type\",\n",
        "    y=\"response_ms\",\n",
        "    color=\"severity\",\n",
        "    title=\"üì¶ Response Time Distribution by Event Type and Severity\",\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    points=\"outliers\",\n",
        "    color_discrete_map={\n",
        "        \"info\": COLORS[\"info\"],\n",
        "        \"warning\": COLORS[\"warning\"],\n",
        "        \"critical\": COLORS[\"danger\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Add SLA threshold\n",
        "fig.add_hline(y=100, line_dash=\"dash\", line_color=COLORS[\"danger\"],\n",
        "              annotation_text=\"SLA: 100ms\", annotation_position=\"right\")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Event Type\",\n",
        "    yaxis_title=\"Response Time (ms)\",\n",
        "    height=450,\n",
        "    legend_title=\"Severity\",\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Calculate SLA violations\n",
        "sla_violations = events_df[events_df[\"response_ms\"] > 100]\n",
        "print(f\"\\n‚ö†Ô∏è  SLA Violations (>100ms): {len(sla_violations)} events ({100*len(sla_violations)/len(events_df):.1f}%)\")\n",
        "print(f\"   By severity: {sla_violations['severity'].value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "## 4. Time Series Visualization\n",
        "\n",
        "Time series help identify:\n",
        "- Attack timing patterns\n",
        "- Baseline vs anomalous periods\n",
        "- Trend analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Traffic timeline with anomaly highlighting\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# Normal traffic\n",
        "normal_traffic = traffic_df[~traffic_df[\"is_anomaly\"]]\n",
        "anomaly_traffic = traffic_df[traffic_df[\"is_anomaly\"]]\n",
        "\n",
        "# Requests line\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=traffic_df[\"hour\"],\n",
        "        y=traffic_df[\"requests\"],\n",
        "        name=\"Requests\",\n",
        "        mode=\"lines+markers\",\n",
        "        line=dict(color=COLORS[\"primary\"], width=2),\n",
        "        marker=dict(size=8),\n",
        "        hovertemplate=\"Hour %{x}<br>Requests: %{y:,}<extra></extra>\",\n",
        "    ),\n",
        "    secondary_y=False,\n",
        ")\n",
        "\n",
        "# Anomaly markers\n",
        "if not anomaly_traffic.empty:\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=anomaly_traffic[\"hour\"],\n",
        "            y=anomaly_traffic[\"requests\"],\n",
        "            name=\"‚ö†Ô∏è Anomaly\",\n",
        "            mode=\"markers\",\n",
        "            marker=dict(color=COLORS[\"danger\"], size=18, symbol=\"x\", line=dict(width=2)),\n",
        "            customdata=anomaly_traffic[\"z_score\"].values,\n",
        "            hovertemplate=\"‚ö†Ô∏è ANOMALY<br>Hour %{x}<br>Requests: %{y:,}<br>Z-score: %{customdata:.2f}<extra></extra>\",\n",
        "        ),\n",
        "        secondary_y=False,\n",
        "    )\n",
        "\n",
        "# Error rate\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=traffic_df[\"hour\"],\n",
        "        y=traffic_df[\"errors\"],\n",
        "        name=\"Errors\",\n",
        "        mode=\"lines+markers\",\n",
        "        line=dict(color=COLORS[\"warning\"], width=2, dash=\"dot\"),\n",
        "        marker=dict(size=6),\n",
        "        hovertemplate=\"Hour %{x}<br>Errors: %{y}<extra></extra>\",\n",
        "    ),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "# Add baseline reference\n",
        "fig.add_hline(y=baseline[\"mean\"], line_dash=\"dash\", line_color=\"gray\",\n",
        "              annotation_text=f\"Baseline: {baseline['mean']:.0f}\", annotation_position=\"right\",\n",
        "              secondary_y=False)\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"üìà Network Traffic Over 24 Hours (with Anomaly Detection)\",\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    height=500,\n",
        "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
        "    hovermode=\"x unified\",\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Hour of Day\", dtick=2)\n",
        "fig.update_yaxes(title_text=\"Request Count\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"Error Count\", secondary_y=True)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Event timeline by severity\n",
        "events_df[\"hour\"] = events_df[\"timestamp\"].dt.hour\n",
        "hourly_severity = events_df.groupby([\"hour\", \"severity\"]).size().unstack(fill_value=0)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for severity in [\"info\", \"warning\", \"critical\"]:\n",
        "    if severity in hourly_severity.columns:\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=hourly_severity.index,\n",
        "                y=hourly_severity[severity],\n",
        "                name=severity.capitalize(),\n",
        "                marker_color={\n",
        "                    \"info\": COLORS[\"info\"],\n",
        "                    \"warning\": COLORS[\"warning\"],\n",
        "                    \"critical\": COLORS[\"danger\"],\n",
        "                }[severity],\n",
        "            )\n",
        "        )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"‚è∞ Security Events by Hour and Severity (Stacked)\",\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    barmode=\"stack\",\n",
        "    xaxis_title=\"Hour of Day\",\n",
        "    yaxis_title=\"Event Count\",\n",
        "    height=400,\n",
        "    legend_title=\"Severity\",\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Find attack window\n",
        "critical_by_hour = events_df[events_df[\"severity\"] == \"critical\"].groupby(\"hour\").size()\n",
        "if not critical_by_hour.empty:\n",
        "    peak_hour = critical_by_hour.idxmax()\n",
        "    print(f\"\\nüö® Attack Window Detected: Hour {peak_hour} has highest critical events ({critical_by_hour.max()})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## 5. Correlation Analysis\n",
        "\n",
        "Correlation helps identify:\n",
        "- Related security metrics\n",
        "- Feature selection for ML\n",
        "- Attack indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Improved Correlation Heatmap - easier to interpret\n",
        "corr_cols = [\"requests\", \"bytes_in\", \"bytes_out\", \"errors\"]\n",
        "corr_matrix = traffic_df[corr_cols].corr()\n",
        "\n",
        "# Human-readable labels\n",
        "label_map = {\n",
        "    \"requests\": \"Requests\",\n",
        "    \"bytes_in\": \"Bytes In\",\n",
        "    \"bytes_out\": \"Bytes Out\",\n",
        "    \"errors\": \"Errors\"\n",
        "}\n",
        "display_labels = [label_map[c] for c in corr_cols]\n",
        "\n",
        "# Mask upper triangle (correlation matrix is symmetric)\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
        "masked_corr = corr_matrix.copy()\n",
        "masked_corr = masked_corr.where(~mask)\n",
        "\n",
        "# Create annotation text with significance markers\n",
        "# *** = very strong (>0.9), ** = strong (>0.7), * = moderate (>0.5)\n",
        "def annotate_corr(val):\n",
        "    if pd.isna(val):\n",
        "        return \"\"\n",
        "    abs_val = abs(val)\n",
        "    stars = \"***\" if abs_val > 0.9 else \"**\" if abs_val > 0.7 else \"*\" if abs_val > 0.5 else \"\"\n",
        "    return f\"{val:.2f}{stars}\"\n",
        "\n",
        "annotations = [[annotate_corr(masked_corr.iloc[i, j]) for j in range(len(corr_cols))]\n",
        "               for i in range(len(corr_cols))]\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=go.Heatmap(\n",
        "        z=masked_corr.values,\n",
        "        x=display_labels,\n",
        "        y=display_labels,\n",
        "        colorscale=\"RdBu_r\",\n",
        "        zmid=0,\n",
        "        zmin=-1,\n",
        "        zmax=1,\n",
        "        text=annotations,\n",
        "        texttemplate=\"%{text}\",\n",
        "        textfont={\"size\": 16, \"color\": \"black\"},\n",
        "        hovertemplate=\"<b>%{y}</b> vs <b>%{x}</b><br>Correlation: %{z:.3f}<extra></extra>\",\n",
        "        colorbar=dict(\n",
        "            title=\"Correlation\",\n",
        "            titleside=\"right\",\n",
        "            tickvals=[-1, -0.5, 0, 0.5, 1],\n",
        "            ticktext=[\"‚àí1 (inverse)\", \"‚àí0.5\", \"0 (none)\", \"+0.5\", \"+1 (strong)\"],\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(\n",
        "        text=\"üî• Feature Correlation Matrix<br><sup>Stars indicate strength: *** >0.9, ** >0.7, * >0.5</sup>\",\n",
        "        font=dict(size=16),\n",
        "    ),\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    height=500,\n",
        "    width=600,\n",
        "    xaxis=dict(side=\"bottom\", tickangle=0),\n",
        "    yaxis=dict(autorange=\"reversed\"),  # Match matrix convention\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Interpretation guide\n",
        "print(\"\\nüìä How to Read This Matrix:\")\n",
        "print(\"   ‚Ä¢ Diagonal = 1.00 (variable correlates perfectly with itself)\")\n",
        "print(\"   ‚Ä¢ Upper triangle hidden (matrix is symmetric)\")\n",
        "print(\"   ‚Ä¢ Blue = positive correlation (both increase together)\")\n",
        "print(\"   ‚Ä¢ Red = negative correlation (one increases, other decreases)\")\n",
        "print(\"   ‚Ä¢ Stars = strength: *** very strong, ** strong, * moderate\")\n",
        "\n",
        "# Key findings\n",
        "print(\"\\nüîç Key Correlations Found:\")\n",
        "for i, col1 in enumerate(corr_cols):\n",
        "    for j, col2 in enumerate(corr_cols):\n",
        "        if i > j:  # Lower triangle only\n",
        "            corr = corr_matrix.loc[col1, col2]\n",
        "            if abs(corr) > 0.5:\n",
        "                strength = \"Very strong\" if abs(corr) > 0.9 else \"Strong\" if abs(corr) > 0.7 else \"Moderate\"\n",
        "                direction = \"‚Üë‚Üë\" if corr > 0 else \"‚Üë‚Üì\"\n",
        "                meaning = \"increase together\" if corr > 0 else \"inverse relationship\"\n",
        "                print(f\"   {label_map[col1]} ‚Üî {label_map[col2]}: {strength} ({corr:.2f}) {direction}\")\n",
        "                print(f\"      ‚Üí {meaning}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plot with correlation - bytes analysis\n",
        "traffic_df[\"error_rate\"] = traffic_df[\"errors\"] / traffic_df[\"requests\"] * 100\n",
        "\n",
        "fig = px.scatter(\n",
        "    traffic_df,\n",
        "    x=\"requests\",\n",
        "    y=\"errors\",\n",
        "    size=\"bytes_in\",\n",
        "    color=\"is_anomaly\",\n",
        "    title=\"üîó Request vs Error Analysis (size = bytes, color = anomaly)\",\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    color_discrete_map={True: COLORS[\"danger\"], False: COLORS[\"primary\"]},\n",
        "    hover_data=[\"hour\", \"error_rate\"],\n",
        ")\n",
        "\n",
        "# Add trend line for normal traffic\n",
        "normal = traffic_df[~traffic_df[\"is_anomaly\"]]\n",
        "z = np.polyfit(normal[\"requests\"], normal[\"errors\"], 1)\n",
        "p = np.poly1d(z)\n",
        "x_line = np.linspace(normal[\"requests\"].min(), normal[\"requests\"].max(), 100)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=x_line,\n",
        "        y=p(x_line),\n",
        "        mode=\"lines\",\n",
        "        name=\"Expected Error Rate\",\n",
        "        line=dict(dash=\"dash\", color=\"gray\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Requests\",\n",
        "    yaxis_title=\"Errors\",\n",
        "    height=450,\n",
        "    legend_title=\"Is Anomaly\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "## 6. Security Dashboard\n",
        "\n",
        "Combine multiple visualizations into a comprehensive SOC dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive security dashboard\n",
        "fig = make_subplots(\n",
        "    rows=2,\n",
        "    cols=3,\n",
        "    subplot_titles=[\n",
        "        \"üìà Traffic Timeline\",\n",
        "        \"üéØ Threat Score Distribution\",\n",
        "        \"‚ö†Ô∏è Events by Severity\",\n",
        "        \"üåê Top Source IPs\",\n",
        "        \"üìä Event Types\",\n",
        "        \"‚è±Ô∏è Response Time\",\n",
        "    ],\n",
        "    specs=[\n",
        "        [{}, {}, {}],\n",
        "        [{}, {}, {}],\n",
        "    ],\n",
        "    vertical_spacing=0.15,\n",
        "    horizontal_spacing=0.08,\n",
        ")\n",
        "\n",
        "# 1. Traffic timeline\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=traffic_df[\"hour\"],\n",
        "        y=traffic_df[\"requests\"],\n",
        "        mode=\"lines+markers\",\n",
        "        name=\"Requests\",\n",
        "        line=dict(color=COLORS[\"primary\"]),\n",
        "        showlegend=False,\n",
        "    ),\n",
        "    row=1, col=1,\n",
        ")\n",
        "\n",
        "# 2. Threat score histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=threat_scores,\n",
        "        nbinsx=20,\n",
        "        marker_color=COLORS[\"warning\"],\n",
        "        showlegend=False,\n",
        "    ),\n",
        "    row=1, col=2,\n",
        ")\n",
        "\n",
        "# 3. Severity pie chart\n",
        "severity_counts = events_df[\"severity\"].value_counts()\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=severity_counts.index,\n",
        "        y=severity_counts.values,\n",
        "        marker_color=[COLORS[\"info\"], COLORS[\"warning\"], COLORS[\"danger\"]][:len(severity_counts)],\n",
        "        showlegend=False,\n",
        "    ),\n",
        "    row=1, col=3,\n",
        ")\n",
        "\n",
        "# 4. Top source IPs\n",
        "ip_counts = events_df[\"source_ip\"].value_counts().head(8)\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=ip_counts.values,\n",
        "        y=ip_counts.index,\n",
        "        orientation=\"h\",\n",
        "        marker_color=COLORS[\"secondary\"],\n",
        "        showlegend=False,\n",
        "    ),\n",
        "    row=2, col=1,\n",
        ")\n",
        "\n",
        "# 5. Event type distribution\n",
        "event_counts = events_df[\"event_type\"].value_counts()\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=event_counts.index,\n",
        "        y=event_counts.values,\n",
        "        marker_color=COLORS[\"info\"],\n",
        "        showlegend=False,\n",
        "    ),\n",
        "    row=2, col=2,\n",
        ")\n",
        "\n",
        "# 6. Response time box\n",
        "fig.add_trace(\n",
        "    go.Box(\n",
        "        y=events_df[\"response_ms\"],\n",
        "        marker_color=COLORS[\"primary\"],\n",
        "        showlegend=False,\n",
        "    ),\n",
        "    row=2, col=3,\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title=dict(\n",
        "        text=\"üîí Security Operations Center Dashboard\",\n",
        "        font=dict(size=22),\n",
        "    ),\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    height=650,\n",
        "    width=1100,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nüìã Dashboard Summary:\")\n",
        "print(f\"   Total Events: {len(events_df)}\")\n",
        "print(f\"   Critical Events: {(events_df['severity'] == 'critical').sum()}\")\n",
        "print(f\"   Traffic Anomalies: {traffic_df['is_anomaly'].sum()}\")\n",
        "print(f\"   High-Risk Scores: {(threat_scores >= 0.7).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "## 7. Advanced: Attack Timeline Reconstruction\n",
        "\n",
        "Use visualization to reconstruct attack progression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attack timeline with event progression\n",
        "events_df[\"severity_num\"] = events_df[\"severity\"].map({\"info\": 1, \"warning\": 2, \"critical\": 3})\n",
        "\n",
        "fig = px.scatter(\n",
        "    events_df,\n",
        "    x=\"timestamp\",\n",
        "    y=\"event_type\",\n",
        "    color=\"severity\",\n",
        "    size=\"severity_num\",\n",
        "    title=\"üïê Attack Timeline Reconstruction\",\n",
        "    template=PLOTLY_TEMPLATE,\n",
        "    color_discrete_map={\n",
        "        \"info\": COLORS[\"info\"],\n",
        "        \"warning\": COLORS[\"warning\"],\n",
        "        \"critical\": COLORS[\"danger\"],\n",
        "    },\n",
        "    hover_data=[\"source_ip\", \"user\", \"success\", \"response_ms\"],\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Time\",\n",
        "    yaxis_title=\"Event Type\",\n",
        "    height=450,\n",
        "    legend_title=\"Severity\",\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Attack chain analysis\n",
        "print(\"\\nüîç Attack Chain Analysis:\")\n",
        "critical_events = events_df[events_df[\"severity\"] == \"critical\"].sort_values(\"timestamp\")\n",
        "for i, (_, event) in enumerate(critical_events.head(5).iterrows()):\n",
        "    print(f\"   Step {i+1}: {event['event_type']} from {event['source_ip']} ({event['timestamp'].strftime('%H:%M')})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "| Skill | Application |\n",
        "|-------|-------------|\n",
        "| Baseline Statistics | Establishing normal behavior |\n",
        "| Z-Score Analysis | Anomaly detection and scoring |\n",
        "| Distribution Plots | Understanding data spread |\n",
        "| Time Series | Attack timeline analysis |\n",
        "| Correlation Heatmaps | Feature relationships |\n",
        "| Dashboards | SOC operations overview |\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Always start with statistics** before visualization\n",
        "2. **Use appropriate chart types** for your data and question\n",
        "3. **Add interactivity** for exploration (hover, zoom, filter)\n",
        "4. **Highlight anomalies** to draw attention to issues\n",
        "5. **Combine views** in dashboards for comprehensive monitoring\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Lab 01**: Apply to phishing classification (confusion matrix, ROC)\n",
        "- **Lab 02**: Visualize malware clustering (t-SNE, PCA)\n",
        "- **Lab 03**: Build anomaly detection dashboards"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
