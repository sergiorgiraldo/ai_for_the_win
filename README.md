# AI for the Win

### Build AI-Powered Security Tools | From Zero to Production

[![CI](https://github.com/depalmar/ai_for_the_win/actions/workflows/ci.yml/badge.svg)](https://github.com/depalmar/ai_for_the_win/actions/workflows/ci.yml)
[![Tests](https://img.shields.io/badge/tests-839%2F839%20passing-brightgreen)](https://github.com/depalmar/ai_for_the_win/actions/workflows/ci.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab01_phishing_classifier.ipynb)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](./Dockerfile)

A hands-on training program for security practitioners who want to build AI-powered tools for threat detection, incident response, and security automation. **25 labs** (including 5 intro labs), **4 capstone projects**, **15 CTF challenges**. Includes **sample datasets** and **solution walkthroughs**. Designed for **vibe coding** with AI assistants like Cursor, Claude Code, and Copilot.

---

## Get Started in 5 Minutes

### Option 1: Zero Setup (Google Colab)

No installation needed ‚Äî run labs directly in your browser:

[![Open Lab 01 in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab01_phishing_classifier.ipynb) [![Open Lab 04 in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab04_llm_log_analysis.ipynb)

> All notebooks are in the [`notebooks/`](./notebooks/) folder ‚Äî open any `.ipynb` file in Colab.

### Option 2: Local Setup

```bash
# 1. Clone the repository
git clone https://github.com/depalmar/ai_for_the_win.git
cd ai_for_the_win

# 2. Install Python dependencies
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate
pip install -r requirements.txt

# 3. Start with Lab 00 (environment setup) - NO API KEY NEEDED!
cd labs/lab00-environment-setup
cat README.md  # Read the lab instructions

# 4. Work through intro labs: 00a ‚Üí 00b ‚Üí 00c ‚Üí 00d ‚Üí 01
# Or jump straight to Lab 01 if you know Python/ML basics
cd ../lab01-phishing-classifier
python solution/main.py
```

### Ready for LLM-Powered Labs? (Labs 04+)

```bash
# Configure API key (choose ONE provider)
cp .env.example .env
echo "ANTHROPIC_API_KEY=your-key-here" >> .env  # Get from console.anthropic.com
# OR use OpenAI/Google - see .env.example for all options

# Verify your setup
python scripts/verify_setup.py

# Run your first LLM lab
cd labs/lab04-llm-log-analysis
python solution/main.py
```

> üìñ **New to Python or ML?** Start with Labs 00a-00b-01-02-03 (no API keys required!)
> üìñ **Know ML, want LLMs?** Jump to Lab 04 and get an API key first
> üìñ **Need help?** Read [GETTING_STARTED.md](./GETTING_STARTED.md) for detailed setup
> üìñ **Lost in the docs?** See [DOCUMENTATION_GUIDE.md](./DOCUMENTATION_GUIDE.md) for navigation

---

## What It Looks Like

<!-- TODO: Add screenshots. See docs/assets/README.md for guidance -->

**Lab 01 - Phishing Classifier** catches what rules miss:

```
$ python labs/lab01-phishing-classifier/solution/main.py

[+] Trained on 1,000 labeled emails
[+] Model: Random Forest with TF-IDF features

Testing on new emails...
  "Dear user, your account will be suspended" ‚Üí üö® PHISHING (94%)
  "Q3 revenue report attached"               ‚Üí ‚úÖ LEGIT (91%)
  "Coinbase: verify identity immediately"    ‚Üí üö® PHISHING (97%)

Top phishing indicators learned:
  1. urgency_score    (+0.34)  ‚Üê "immediately", "suspend", "verify"
  2. url_mismatch     (+0.28)  ‚Üê display text ‚â† actual link
  3. sender_anomaly   (+0.19)  ‚Üê domain doesn't match brand
```

**Lab 04 - LLM Log Analysis** finds attacks in noise:

```
$ python labs/lab04-llm-log-analysis/solution/main.py

[1/3] Pre-filtering 10,000 auth events...
[2/3] Found 23 anomalous patterns ‚Üí sending to Claude
[3/3] AI analysis complete

üî¥ ATTACK CHAIN DETECTED

  Stage 1: Credential Stuffing
    Source: 45.33.32.156 (Tor exit node)
    847 failed logins ‚Üí 12 accounts compromised
    ‚ö†Ô∏è  All 12 had MFA disabled
    ‚Üí MITRE ATT&CK: T1110.004

  Stage 2: Lateral Movement (15 min later)
    'svc_backup' ‚Üí SMB to FILE01, FILE02, DC01
    ‚ö†Ô∏è  Includes domain controller
    ‚Üí MITRE ATT&CK: T1021.002 (SMB/Windows Admin Shares)

  Timeline: 02:14 initial access ‚Üí 02:29 lateral spread

Action: Isolate FILE01/FILE02/DC01, reset 12 accounts, enforce MFA
```

---

## Interactive Lab Navigator

**Click any lab to explore** ‚Äî Your learning journey from setup to expert:

```mermaid
flowchart LR
    subgraph S[" "]
        direction LR
        A["‚ö™ Foundations<br/>00-00d"] --> B["üü¢ ML Basics<br/>01-03"] --> C["üü° LLM<br/>04-07"] --> D["üü† Advanced<br/>08-10"] --> E["üî¥ Expert<br/>11-20"]
    end
```

<table>
<tr>
<td align="center"><a href="./labs/lab00-environment-setup/"><img src="https://img.shields.io/badge/00-Setup-gray?style=for-the-badge" alt="Lab 00"/></a></td>
<td align="center"><a href="./labs/lab00a-python-security-fundamentals/"><img src="https://img.shields.io/badge/00a-Python-gray?style=for-the-badge" alt="Lab 00a"/></a></td>
<td align="center"><a href="./labs/lab00b-ml-concepts-primer/"><img src="https://img.shields.io/badge/00b-ML_Intro-gray?style=for-the-badge" alt="Lab 00b"/></a></td>
<td align="center"><a href="./labs/lab00c-intro-prompt-engineering/"><img src="https://img.shields.io/badge/00c-Prompts-gray?style=for-the-badge" alt="Lab 00c"/></a></td>
<td align="center"><a href="./labs/lab00d-ai-in-security-operations/"><img src="https://img.shields.io/badge/00d-AI_in_SOC-gray?style=for-the-badge" alt="Lab 00d"/></a></td>
</tr>
<tr>
<td align="center"><a href="./labs/lab01-phishing-classifier/"><img src="https://img.shields.io/badge/01-Phishing-10b981?style=for-the-badge" alt="Lab 01"/></a></td>
<td align="center"><a href="./labs/lab02-malware-clustering/"><img src="https://img.shields.io/badge/02-Malware-10b981?style=for-the-badge" alt="Lab 02"/></a></td>
<td align="center"><a href="./labs/lab03-anomaly-detection/"><img src="https://img.shields.io/badge/03-Anomaly-10b981?style=for-the-badge" alt="Lab 03"/></a></td>
<td align="center"><a href="./labs/lab04-llm-log-analysis/"><img src="https://img.shields.io/badge/04-Logs-6366f1?style=for-the-badge" alt="Lab 04"/></a></td>
<td align="center"><a href="./labs/lab05-threat-intel-agent/"><img src="https://img.shields.io/badge/05-Intel-6366f1?style=for-the-badge" alt="Lab 05"/></a></td>
</tr>
<tr>
<td align="center"><a href="./labs/lab06-security-rag/"><img src="https://img.shields.io/badge/06-RAG-6366f1?style=for-the-badge" alt="Lab 06"/></a></td>
<td align="center"><a href="./labs/lab07-yara-generator/"><img src="https://img.shields.io/badge/07-YARA-6366f1?style=for-the-badge" alt="Lab 07"/></a></td>
<td align="center"><a href="./labs/lab08-vuln-prioritizer/"><img src="https://img.shields.io/badge/08-Vuln-f59e0b?style=for-the-badge" alt="Lab 08"/></a></td>
<td align="center"><a href="./labs/lab09-detection-pipeline/"><img src="https://img.shields.io/badge/09-Pipeline-f59e0b?style=for-the-badge" alt="Lab 09"/></a></td>
<td align="center"><a href="./labs/lab10-ir-copilot/"><img src="https://img.shields.io/badge/10-IR_Bot-f59e0b?style=for-the-badge" alt="Lab 10"/></a></td>
</tr>
<tr>
<td align="center"><a href="./labs/lab11-ransomware-detection/"><img src="https://img.shields.io/badge/11-Ransom-ef4444?style=for-the-badge" alt="Lab 11"/></a></td>
<td align="center"><a href="./labs/lab12-ransomware-simulation/"><img src="https://img.shields.io/badge/12-Purple-ef4444?style=for-the-badge" alt="Lab 12"/></a></td>
<td align="center"><a href="./labs/lab13-memory-forensics-ai/"><img src="https://img.shields.io/badge/13-Memory-ef4444?style=for-the-badge" alt="Lab 13"/></a></td>
<td align="center"><a href="./labs/lab14-c2-traffic-analysis/"><img src="https://img.shields.io/badge/14-C2-ef4444?style=for-the-badge" alt="Lab 14"/></a></td>
<td align="center"><a href="./labs/lab15-lateral-movement-detection/"><img src="https://img.shields.io/badge/15-Lateral-ef4444?style=for-the-badge" alt="Lab 15"/></a></td>
</tr>
<tr>
<td align="center"><a href="./labs/lab16-threat-actor-profiling/"><img src="https://img.shields.io/badge/16-Actors-ef4444?style=for-the-badge" alt="Lab 16"/></a></td>
<td align="center"><a href="./labs/lab17-adversarial-ml/"><img src="https://img.shields.io/badge/17-AdvML-ef4444?style=for-the-badge" alt="Lab 17"/></a></td>
<td align="center"><a href="./labs/lab18-fine-tuning-security/"><img src="https://img.shields.io/badge/18-Tuning-ef4444?style=for-the-badge" alt="Lab 18"/></a></td>
<td align="center"><a href="./labs/lab19-cloud-security-ai/"><img src="https://img.shields.io/badge/19-Cloud-ef4444?style=for-the-badge" alt="Lab 19"/></a></td>
<td align="center"><a href="./labs/lab20-llm-red-teaming/"><img src="https://img.shields.io/badge/20-RedTeam-ef4444?style=for-the-badge" alt="Lab 20"/></a></td>
</tr>
<tr>
<td align="center" colspan="5"><strong>Legend:</strong> ‚ö™ Intro (Free) | üü¢ ML (Free) | üü° LLM | üü† Advanced | üî¥ Expert DFIR</td>
</tr>
</table>

---

## Learning Paths

### Recommended Paths by Background

| Your Background                                | Start Here | Learning Path                                                                                      |
| ---------------------------------------------- | ---------- | -------------------------------------------------------------------------------------------------- |
| **Complete beginner** (no Python)              | Lab 00a    | 00a (Python) ‚Üí 00b (ML theory) ‚Üí 01 (ML hands-on) ‚Üí 02 ‚Üí 03 ‚Üí 04 (LLMs) ‚Üí 00c (advanced prompting) |
| **Know Python**, new to ML                     | Lab 00b    | 00b (ML theory) ‚Üí 01 ‚Üí 02 ‚Üí 03 (ML foundations) ‚Üí 04 ‚Üí 06 ‚Üí 05 (LLM/agents)                        |
| **Know Python & ML**, new to LLMs              | Lab 04     | 04 (basic prompting) ‚Üí 06 (RAG) ‚Üí 05 (agents) ‚Üí 00c (advanced prompting) ‚Üí 07-10                   |
| **Want to build AI agents**                    | Lab 04     | 04 (prompting) ‚Üí 05 (ReAct agents) ‚Üí 06 (RAG) ‚Üí 10 (copilot) ‚Üí Capstone                            |
| **DFIR/SOC analyst**                           | Lab 01     | 01 ‚Üí 03 (ML detection) ‚Üí 04 (log analysis) ‚Üí 11 (ransomware) ‚Üí 13 (memory forensics)               |
| **Red Team/Offensive**                         | Lab 03     | 03 (anomaly det) ‚Üí 12 (purple team) ‚Üí 14 (C2) ‚Üí 15 (lateral movement) ‚Üí 17 (adversarial ML)        |
| **Threat Intel analyst**                       | Lab 04     | 04 (log analysis) ‚Üí 05 (threat intel agent) ‚Üí 06 (RAG) ‚Üí 14 (C2) ‚Üí 16 (actor profiling)            |
| **Security engineer** (build production tools) | Lab 01     | 01 ‚Üí 03 ‚Üí 04 ‚Üí 08 (vuln scanner) ‚Üí 09 (pipeline) ‚Üí 10 (IR copilot) ‚Üí Capstone                      |

**üí° Pro Tip**: Labs 01-03 require NO API keys - perfect for learning ML foundations cost-free! Get comfortable with ML before moving to LLM-powered labs (04+).

---

## What You'll Build

### Labs Overview

| Lab     | Project                         | What You'll Learn                                                                                         |
| ------- | ------------------------------- | --------------------------------------------------------------------------------------------------------- |
| **00a** | **Python for Security**         | Variables, files, APIs, regex, security-focused Python basics                                             |
| **00b** | **ML Concepts Primer**          | Supervised/unsupervised learning, features, training, evaluation metrics                                  |
| **00c** | **Intro to Prompt Engineering** | LLM basics with free playgrounds, prompting fundamentals, hallucination detection, security templates     |
| **00d** | **AI in Security Operations**   | Where AI fits in SOC, human-in-the-loop, AI as attack surface, compliance considerations                  |
| **01**  | **Phishing Classifier**         | Text preprocessing, TF-IDF vectorization, Random Forest classification, model evaluation metrics          |
| **02**  | **Malware Clusterer**           | Feature extraction from binaries, K-Means & DBSCAN clustering, dimensionality reduction, cluster analysis |
| **03**  | **Anomaly Detector**            | Statistical baselines, Isolation Forest, Local Outlier Factor, threshold optimization for security        |
| **04**  | **Log Analyzer**                | Prompt engineering for security, structured output parsing, IOC extraction, LLM-powered analysis          |
| **05**  | **Threat Intel Agent**          | ReAct pattern implementation, tool use with LangChain, autonomous investigation workflows                 |
| **06**  | **Security RAG**                | Document chunking, vector embeddings, ChromaDB, retrieval-augmented generation for Q&A                    |
| **07**  | **YARA Generator**              | Static malware analysis, pattern extraction, AI-assisted rule generation, rule validation                 |
| **08**  | **Vuln Prioritizer**            | CVSS scoring, risk-based prioritization, remediation planning with LLMs                                   |
| **09**  | **Detection Pipeline**          | Multi-stage architectures, ML filtering, LLM enrichment, alert correlation                                |
| **10**  | **IR Copilot**                  | Conversational agents, state management, playbook execution, incident documentation                       |
| **11**  | **Ransomware Detector**         | Entropy analysis, behavioral detection, ransom note IOC extraction, response automation                   |
| **12**  | **Purple Team Sim**             | Safe adversary emulation, detection validation, gap analysis, purple team exercises                       |
| **13**  | **Memory Forensics AI**         | Volatility3 integration, process injection detection, credential dumping, LLM artifact analysis           |
| **14**  | **C2 Traffic Analysis**         | Beaconing detection, DNS tunneling, encrypted C2, JA3 fingerprinting, traffic classification              |
| **15**  | **Lateral Movement Detection**  | Auth anomaly detection, remote execution (PsExec/WMI/WinRM), graph-based attack paths                     |
| **16**  | **Threat Actor Profiling**      | TTP extraction, campaign clustering, malware attribution, actor profile generation                        |
| **17**  | **Adversarial ML**              | Evasion attacks, poisoning attacks, adversarial training, robust ML defenses                              |
| **18**  | **Fine-Tuning for Security**    | Custom embeddings, LoRA fine-tuning, security-specific models, deployment                                 |
| **19**  | **Cloud Security AI**           | AWS/Azure/GCP security, CloudTrail analysis, multi-cloud threat detection                                 |
| **20**  | **LLM Red Teaming**             | Prompt injection, jailbreaking defenses, guardrails, LLM security testing                                 |

### Skills Progression

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INTRO          ‚îÇ  ML FOUNDATIONS   ‚îÇ  LLM BASICS        ‚îÇ  ADVANCED LLM      ‚îÇ  EXPERT         ‚îÇ
‚îÇ  Labs 00a-00c   ‚îÇ  Labs 01-03       ‚îÇ  Labs 04-07        ‚îÇ  Labs 08-10        ‚îÇ  Labs 11-20     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Python       ‚îÇ  ‚Ä¢ Supervised ML  ‚îÇ  ‚Ä¢ Prompt Eng      ‚îÇ  ‚Ä¢ System Design   ‚îÇ  ‚Ä¢ DFIR         ‚îÇ
‚îÇ  ‚Ä¢ ML Theory    ‚îÇ  ‚Ä¢ Unsupervised   ‚îÇ  ‚Ä¢ AI Agents       ‚îÇ  ‚Ä¢ ML+LLM Hybrid   ‚îÇ  ‚Ä¢ Forensics    ‚îÇ
‚îÇ  ‚Ä¢ Prompting    ‚îÇ  ‚Ä¢ Feature Eng    ‚îÇ  ‚Ä¢ RAG Systems     ‚îÇ  ‚Ä¢ Pipelines       ‚îÇ  ‚Ä¢ C2 Detect    ‚îÇ
‚îÇ  (optional)     ‚îÇ  ‚Ä¢ Evaluation     ‚îÇ  ‚Ä¢ Code Gen        ‚îÇ  ‚Ä¢ Production      ‚îÇ  ‚Ä¢ Attribution  ‚îÇ
‚îÇ                 ‚îÇ                   ‚îÇ                    ‚îÇ                    ‚îÇ  ‚Ä¢ Adv ML       ‚îÇ
‚îÇ                 ‚îÇ                   ‚îÇ                    ‚îÇ                    ‚îÇ  ‚Ä¢ LLM Red Team ‚îÇ
‚îÇ  üí∞ FREE        ‚îÇ  üí∞ FREE          ‚îÇ  üí∞ ~$2-8 API      ‚îÇ  üí∞ ~$5-15 API     ‚îÇ  üí∞ ~$10-25    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üí° **Cost-Saving Tip**: Complete Labs 01-03 first (FREE, no API keys) to build ML foundations before
   investing in LLM API credits. Then use free tiers: Anthropic ($5 free), Google AI Studio (free),
   OpenAI ($5 free for new accounts). Costs based on 2025 pricing: Claude 3.5 Sonnet ($3/$15 per 1M
   tokens), GPT-4o ($5/$20 per 1M), Gemini 2.5 Pro ($1.25/$10 per 1M).
```

### When to Use ML vs LLM

| Security Task          | Best Approach | Why                                        |
| ---------------------- | ------------- | ------------------------------------------ |
| Malware classification | **ML**        | Fast, interpretable, structured features   |
| Log anomaly detection  | **ML**        | High volume, real-time capable             |
| Threat report analysis | **LLM**       | Natural language understanding             |
| IOC extraction         | **LLM**       | Flexible parsing of unstructured text      |
| Phishing detection     | **Hybrid**    | ML for volume, LLM for sophisticated cases |
| Detection pipeline     | **Hybrid**    | ML filters 90%, LLM analyzes 10%           |

> üìñ **Full comparison**: See [ML vs LLM Decision Framework](./LEARNING_GUIDE.md#choosing-the-right-tool-ml-vs-llm) for detailed guidance, cost analysis, and hybrid architecture patterns.

---

## Repository Structure

```
ai_for_the_win/
‚îú‚îÄ‚îÄ labs/                          # 25 hands-on labs
‚îÇ   ‚îú‚îÄ‚îÄ lab00-environment-setup/  # Setup guide for beginners
‚îÇ   ‚îú‚îÄ‚îÄ lab00a-python-security-fundamentals/ # Python basics for security
‚îÇ   ‚îú‚îÄ‚îÄ lab00b-ml-concepts-primer/ # ML theory before coding
‚îÇ   ‚îú‚îÄ‚îÄ lab00c-intro-prompt-engineering/ # Prompt design & basics
‚îÇ   ‚îú‚îÄ‚îÄ lab00d-ai-in-security-operations/ # AI in SOC workflows
‚îÇ   ‚îú‚îÄ‚îÄ lab01-phishing-classifier/ # ML text classification
‚îÇ   ‚îú‚îÄ‚îÄ lab02-malware-clustering/  # Unsupervised learning
‚îÇ   ‚îú‚îÄ‚îÄ lab03-anomaly-detection/   # Network security
‚îÇ   ‚îú‚îÄ‚îÄ lab04-llm-log-analysis/    # Prompt engineering
‚îÇ   ‚îú‚îÄ‚îÄ lab05-threat-intel-agent/  # ReAct agents
‚îÇ   ‚îú‚îÄ‚îÄ lab06-security-rag/        # Vector search + LLM
‚îÇ   ‚îú‚îÄ‚îÄ lab07-yara-generator/      # AI code generation
‚îÇ   ‚îú‚îÄ‚îÄ lab08-vuln-scanner-ai/     # Risk prioritization
‚îÇ   ‚îú‚îÄ‚îÄ lab09-detection-pipeline/  # Multi-stage ML+LLM
‚îÇ   ‚îú‚îÄ‚îÄ lab10-ir-copilot/          # Conversational IR
‚îÇ   ‚îú‚îÄ‚îÄ lab11-ransomware-detection/# DFIR + behavioral analysis
‚îÇ   ‚îú‚îÄ‚îÄ lab12-ransomware-simulation/# Purple team exercises
‚îÇ   ‚îú‚îÄ‚îÄ lab13-memory-forensics-ai/ # Memory forensics with AI
‚îÇ   ‚îú‚îÄ‚îÄ lab14-c2-traffic-analysis/ # C2 detection & analysis
‚îÇ   ‚îú‚îÄ‚îÄ lab15-lateral-movement-detection/ # Attack path detection
‚îÇ   ‚îú‚îÄ‚îÄ lab16-threat-actor-profiling/ # Attribution & profiling
‚îÇ   ‚îú‚îÄ‚îÄ lab17-adversarial-ml/     # Evasion & poisoning attacks
‚îÇ   ‚îú‚îÄ‚îÄ lab18-fine-tuning/        # Custom security models
‚îÇ   ‚îú‚îÄ‚îÄ lab19-cloud-security/     # Multi-cloud threat detection
‚îÇ   ‚îî‚îÄ‚îÄ lab20-llm-red-teaming/    # LLM security testing
‚îú‚îÄ‚îÄ notebooks/                     # Jupyter notebooks (Colab-ready)
‚îú‚îÄ‚îÄ capstone-projects/             # 4 comprehensive projects
‚îú‚îÄ‚îÄ templates/                     # Reusable code templates
‚îÇ   ‚îú‚îÄ‚îÄ agents/                    # LangChain agent templates
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                   # Security prompt library
‚îÇ   ‚îú‚îÄ‚îÄ visualizations/            # Dashboards & diagrams
‚îÇ   ‚îî‚îÄ‚îÄ reports/                   # Report generators
‚îú‚îÄ‚îÄ resources/                     # Tools, datasets, MCP servers guide
‚îú‚îÄ‚îÄ setup/                         # Environment setup guides
‚îÇ   ‚îî‚îÄ‚îÄ guides/                    # Troubleshooting & error handling
‚îú‚îÄ‚îÄ tests/                         # Comprehensive test suite
‚îú‚îÄ‚îÄ Dockerfile                     # Multi-stage Docker build
‚îî‚îÄ‚îÄ docker-compose.yml             # Dev, test, notebook services
```

---

## Lab Progress Tracker

Track your progress through the labs:

**Intro (Recommended)**

- [ ] **Lab 00**: Environment Setup (Python, VS Code, virtual env)
- [ ] **Lab 00a**: Python for Security Fundamentals
- [ ] **Lab 00b**: ML Concepts Primer
- [ ] **Lab 00c**: Intro to Prompt Engineering
- [ ] **Lab 00d**: AI in Security Operations (conceptual)

**Core Labs**

- [ ] **Lab 01**: Phishing Email Classifier
- [ ] **Lab 02**: Malware Sample Clustering
- [ ] **Lab 03**: Network Anomaly Detection
- [ ] **Lab 04**: LLM-Powered Log Analysis
- [ ] **Lab 05**: Threat Intelligence Agent
- [ ] **Lab 06**: Security RAG System
- [ ] **Lab 07**: AI YARA Rule Generator
- [ ] **Lab 08**: Vulnerability Scanner AI
- [ ] **Lab 09**: Threat Detection Pipeline
- [ ] **Lab 10**: IR Copilot Agent
- [ ] **Lab 11**: Ransomware Detection & Response
- [ ] **Lab 12**: Ransomware Simulation (Purple Team)
- [ ] **Lab 13**: Memory Forensics AI
- [ ] **Lab 14**: C2 Traffic Analysis
- [ ] **Lab 15**: Lateral Movement Detection
- [ ] **Lab 16**: Threat Actor Profiling
- [ ] **Lab 17**: Adversarial ML
- [ ] **Lab 18**: Fine-tuning Security
- [ ] **Lab 19**: Cloud Security AI
- [ ] **Lab 20**: LLM Red Teaming
- [ ] **Capstone**: Complete one capstone project

---

## Technology Stack

| Category           | Tools                                            |
| ------------------ | ------------------------------------------------ |
| **LLM Providers**  | Claude, GPT-4, Gemini, Ollama (local)            |
| **LLM Frameworks** | LangChain, LangGraph, LiteLLM, Instructor        |
| **ML/AI**          | scikit-learn, PyTorch, Hugging Face Transformers |
| **Vector DB**      | ChromaDB, sentence-transformers                  |
| **Security**       | YARA, Sigma, MITRE ATT&CK, pefile                |
| **Web/UI**         | FastAPI, Gradio, Streamlit                       |
| **Vibe Coding**    | Cursor, Claude Code, GitHub Copilot, Windsurf    |
| **Development**    | Python 3.10+, pytest, Docker, GitHub Actions     |

---

## Capstone Projects

Choose one to demonstrate mastery:

| Project                          | Difficulty   | Focus                     |
| -------------------------------- | ------------ | ------------------------- |
| **Security Analyst Copilot**     | Advanced     | LLM agents, IR automation |
| **Automated Threat Hunter**      | Advanced     | ML detection, pipelines   |
| **Malware Analysis Assistant**   | Intermediate | Static analysis, YARA     |
| **Vulnerability Intel Platform** | Intermediate | RAG, prioritization       |

Each project includes starter code, requirements, and evaluation criteria.

---

## Templates & Integrations

Jumpstart your projects with ready-to-use templates:

- **Agent Templates**: LangChain security agent, RAG agent
- **n8n Workflows**: IOC enrichment, alert triage with AI
- **SIEM Integrations**: Cortex XSIAM, Splunk, Elasticsearch, Microsoft Sentinel
- **Prompt Library**: Log analysis, threat detection, report generation

---

## Development

### Test Status

**Current Status**: 839/839 tests passing (100%) ‚úÖ

All 20 labs have comprehensive test coverage!

| Lab    | Tests | Status  | Focus Area                         |
| ------ | ----- | ------- | ---------------------------------- |
| Lab 01 | 14/14 | ‚úÖ 100% | Phishing Classifier (ML)           |
| Lab 02 | 9/9   | ‚úÖ 100% | Malware Clustering (ML)            |
| Lab 03 | 11/11 | ‚úÖ 100% | Anomaly Detection (ML)             |
| Lab 04 | 18/18 | ‚úÖ 100% | Log Analysis (LLM)                 |
| Lab 05 | 21/21 | ‚úÖ 100% | Threat Intel Agent (LangChain)     |
| Lab 06 | 7/7   | ‚úÖ 100% | Security RAG (Vector DB)           |
| Lab 07 | 8/8   | ‚úÖ 100% | YARA Generator (Code Gen)          |
| Lab 08 | 11/11 | ‚úÖ 100% | Vuln Scanner (Risk Prioritization) |
| Lab 09 | 15/15 | ‚úÖ 100% | Detection Pipeline (Multi-stage)   |
| Lab 10 | 28/28 | ‚úÖ 100% | IR Copilot (Conversational)        |
| Lab 11 | 37/37 | ‚úÖ 100% | Ransomware Detection (DFIR)        |
| Lab 12 | 44/44 | ‚úÖ 100% | Purple Team Sim (Safe Emulation)   |
| Lab 13 | 71/71 | ‚úÖ 100% | Memory Forensics AI                |
| Lab 14 | 85/85 | ‚úÖ 100% | C2 Traffic Analysis                |
| Lab 15 | 69/69 | ‚úÖ 100% | Lateral Movement Detection         |
| Lab 16 | 90/90 | ‚úÖ 100% | Threat Actor Profiling             |
| Lab 17 | 73/73 | ‚úÖ 100% | Adversarial ML                     |
| Lab 18 | 76/76 | ‚úÖ 100% | Fine-Tuning for Security           |
| Lab 19 | 64/64 | ‚úÖ 100% | Cloud Security AI                  |
| Lab 20 | 88/88 | ‚úÖ 100% | LLM Red Teaming                    |

**API Requirements**: Labs 04-20 require at least one LLM provider API key (`ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, or `GOOGLE_API_KEY`). Labs 01-03 work without API keys.

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run specific lab tests
pytest tests/test_lab01_phishing_classifier.py -v

# Run with coverage
pytest tests/ --cov=labs --cov-report=html

# Run in Docker
docker-compose run test
```

### Code Quality

```bash
# Format code
black .
isort .

# Lint
flake8 .

# Security scan
bandit -r labs/
```

### Environment Variables

Copy `.env.example` to `.env` and configure:

| Variable             | Description       | Required                |
| -------------------- | ----------------- | ----------------------- |
| `ANTHROPIC_API_KEY`  | Claude API key    | One LLM key required    |
| `OPENAI_API_KEY`     | OpenAI GPT-4 key  | One LLM key required    |
| `GOOGLE_API_KEY`     | Google Gemini key | One LLM key required    |
| `VIRUSTOTAL_API_KEY` | VirusTotal API    | Optional (threat intel) |
| `ABUSEIPDB_API_KEY`  | AbuseIPDB API     | Optional (threat intel) |

> **Note:** You only need ONE LLM provider key. All labs support multiple providers.

---

## Getting Help

- **New to this?**: Start with [Lab 00: Environment Setup](./labs/lab00-environment-setup/)
- **Find your path**: See [Role-Based Learning Paths](./resources/role-based-learning-paths.md) for SOC, IR, hunting, etc.
- **Confused by AI terms?**: Check the [Security-to-AI Glossary](./resources/security-to-ai-glossary.md)
- **API Keys**: See the [API Keys Guide](./setup/guides/api-keys-guide.md) for setup and cost management
- **Jupyter Notebooks**: Check the [Jupyter Basics Guide](./setup/guides/jupyter-basics-guide.md)
- **Troubleshooting**: Check the [troubleshooting guide](./setup/guides/troubleshooting-guide.md)
- **Error Handling**: See [error handling best practices](./setup/guides/error-handling-guide.md)
- **Documentation**: Browse [setup guides](./setup/) and [resources](./resources/)
- **Issues**: Open a [GitHub issue](https://github.com/depalmar/ai_for_the_win/issues)

---

## Quick Links

| Resource                                                              | Description                                         |
| --------------------------------------------------------------------- | --------------------------------------------------- |
| [Environment Setup](./labs/lab00-environment-setup/)                  | First-time setup for beginners                      |
| [Role-Based Learning Paths](./resources/role-based-learning-paths.md) | Paths for SOC, IR, hunting, red team                |
| [Security-to-AI Glossary](./resources/security-to-ai-glossary.md)     | AI terms explained for security folks               |
| [API Keys Guide](./setup/guides/api-keys-guide.md)                    | Get API keys, manage costs                          |
| [Quick Start](./QUICKSTART.md)                                        | Get running fast                                    |
| [Documentation Guide](./DOCUMENTATION_GUIDE.md)                       | Find exactly what you need                          |
| [Security Prompts](./resources/prompt-library/security-prompts.md)    | Ready-to-use prompts for security tasks             |
| [Lab Walkthroughs](./docs/walkthroughs/)                              | Step-by-step solutions when stuck                   |
| [Cheatsheets](./resources/cheatsheets/)                               | Quick references for Claude Code, Cursor, LangChain |
| [SIEM Integrations](./resources/integrations/)                        | Splunk, Elastic, XSIAM integration guides           |
| [Tools & APIs](./resources/tools-and-resources.md)                    | 80+ security tools, APIs, datasets                  |
| [MCP Servers](./resources/mcp-servers-security-guide.md)              | MCP servers for DFIR, threat intel                  |

---

## Contributing

Contributions welcome! Please read [CONTRIBUTING.md](./CONTRIBUTING.md) before submitting PRs.

Ways to contribute:

- Fix bugs or improve existing labs
- Add new sample data or test cases
- Improve documentation
- Share your capstone projects

---

## License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.

---

## Disclaimer

This training material is intended for **educational purposes** and **authorized security testing only**. Users are responsible for ensuring compliance with all applicable laws and obtaining proper authorization before using any offensive techniques.

---

<p align="center">
  <b>Ready to build AI-powered security tools?</b><br>
  <a href="./labs/lab00-environment-setup/">Get Started</a> |
  <a href="./curriculum/ai-security-training-program.md">View Full Curriculum</a>
</p>
