#!/usr/bin/env python3
"""
Lab 02: Malware Sample Clustering - Starter Code

Use unsupervised learning to cluster malware samples by behavior and characteristics.

Instructions:
1. Complete each TODO section
2. Run with sample data in data/ folder
3. Compare your results with the solution
"""

import pandas as pd
import numpy as np
from typing import List, Tuple, Optional
from pathlib import Path

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score

import matplotlib.pyplot as plt
import seaborn as sns


# =============================================================================
# Task 1: Load Sample Data
# =============================================================================

def load_malware_data(filepath: str) -> pd.DataFrame:
    """
    Load pre-extracted malware features.

    Features include:
    - file_size: Size in bytes
    - entropy: Shannon entropy
    - num_imports: Number of imported functions
    - num_sections: Number of PE sections
    - has_debug: Debug info present
    - has_signature: Digital signature present
    - imphash: Import hash (categorical)
    - family: Known malware family (for evaluation)

    TODO:
    1. Load CSV file
    2. Handle missing values
    3. Print dataset statistics
    4. Return DataFrame
    """
    # YOUR CODE HERE
    pass


def explore_data(df: pd.DataFrame) -> None:
    """
    Print exploratory statistics about the dataset.

    TODO:
    1. Print shape and columns
    2. Show value counts for categorical columns
    3. Show statistics for numeric columns
    4. Check for missing values
    """
    # YOUR CODE HERE
    pass


# =============================================================================
# Task 2: Feature Engineering
# =============================================================================

def engineer_features(df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
    """
    Prepare features for clustering.

    TODO:
    1. Select numeric features
    2. Handle categorical features (one-hot or label encoding)
    3. Apply log transform to skewed features (file_size)
    4. Normalize/standardize features
    5. Return feature matrix and feature names

    Consider:
    - Log transform for file_size (highly skewed)
    - Standard scaling for clustering algorithms
    - Handle any outliers
    """
    # YOUR CODE HERE
    pass


# =============================================================================
# Task 3: Dimensionality Reduction
# =============================================================================

def reduce_dimensions(X: np.ndarray, method: str = 'pca') -> np.ndarray:
    """
    Reduce feature dimensions for visualization.

    Args:
        X: Feature matrix
        method: 'pca', 'tsne', or 'umap'

    Returns:
        2D representation

    TODO:
    1. Apply PCA for initial reduction (if high-dimensional)
    2. Apply t-SNE or UMAP for visualization
    3. Return 2D coordinates
    """
    # YOUR CODE HERE
    pass


# =============================================================================
# Task 4: Clustering
# =============================================================================

def find_optimal_k(X: np.ndarray, k_range: range = range(2, 10)) -> int:
    """
    Find optimal number of clusters using silhouette score.

    TODO:
    1. Try different values of k
    2. Calculate silhouette score for each
    3. Return optimal k
    """
    # YOUR CODE HERE
    pass


def cluster_samples(X: np.ndarray, method: str = 'kmeans', n_clusters: int = None) -> np.ndarray:
    """
    Cluster malware samples.

    Args:
        X: Feature matrix (or reduced features)
        method: 'kmeans', 'dbscan', or 'hierarchical'
        n_clusters: Number of clusters (for kmeans)

    Returns:
        Cluster labels

    TODO:
    1. If n_clusters not provided, find optimal k
    2. Apply selected clustering algorithm
    3. Evaluate clustering quality
    4. Return cluster labels
    """
    # YOUR CODE HERE
    pass


# =============================================================================
# Task 5: Visualization
# =============================================================================

def visualize_clusters(
    X_2d: np.ndarray,
    labels: np.ndarray,
    title: str = "Malware Clusters",
    save_path: str = None
) -> None:
    """
    Visualize clustering results.

    TODO:
    1. Create scatter plot with cluster colors
    2. Add legend and labels
    3. Optionally save figure
    """
    # YOUR CODE HERE
    pass


def compare_with_families(
    X_2d: np.ndarray,
    cluster_labels: np.ndarray,
    family_labels: np.ndarray
) -> None:
    """
    Compare clustering with known malware families.

    TODO:
    1. Create side-by-side plots
    2. Left: cluster assignments
    3. Right: actual family labels
    4. Calculate agreement metrics
    """
    # YOUR CODE HERE
    pass


# =============================================================================
# Task 6: Analysis
# =============================================================================

def analyze_clusters(df: pd.DataFrame, labels: np.ndarray) -> dict:
    """
    Analyze characteristics of each cluster.

    Returns:
        Dict with cluster statistics:
        - size: Number of samples
        - avg_entropy: Average entropy
        - avg_size: Average file size
        - common_features: Distinguishing features
        - suspected_family: Likely malware family

    TODO:
    1. Group samples by cluster
    2. Calculate statistics per cluster
    3. Identify distinguishing features
    4. Return analysis dict
    """
    # YOUR CODE HERE
    pass


def print_cluster_report(analysis: dict) -> None:
    """Print formatted cluster analysis report."""
    # YOUR CODE HERE
    pass


# =============================================================================
# Main Execution
# =============================================================================

def main():
    """Main execution flow."""
    print("=" * 60)
    print("Lab 02: Malware Sample Clustering")
    print("=" * 60)

    # Load data
    data_path = Path(__file__).parent.parent / "data" / "malware_features.csv"

    if not data_path.exists():
        print(f"Data file not found: {data_path}")
        print("Creating sample data...")
        create_sample_data(data_path)

    print("\n[Step 1] Loading data...")
    df = load_malware_data(str(data_path))

    if df is None:
        print("Error: load_malware_data() returned None. Complete the TODO!")
        return

    explore_data(df)

    # Feature engineering
    print("\n[Step 2] Engineering features...")
    result = engineer_features(df)

    if result is None:
        print("Error: engineer_features() returned None. Complete the TODO!")
        return

    X, feature_names = result
    print(f"Feature matrix shape: {X.shape}")

    # Dimensionality reduction
    print("\n[Step 3] Reducing dimensions...")
    X_2d = reduce_dimensions(X, method='tsne')

    if X_2d is None:
        print("Error: reduce_dimensions() returned None. Complete the TODO!")
        return

    # Clustering
    print("\n[Step 4] Clustering samples...")
    labels = cluster_samples(X, method='kmeans')

    if labels is None:
        print("Error: cluster_samples() returned None. Complete the TODO!")
        return

    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    print(f"Found {n_clusters} clusters")

    # Calculate silhouette score
    if n_clusters > 1:
        score = silhouette_score(X, labels)
        print(f"Silhouette Score: {score:.3f}")

    # Visualization
    print("\n[Step 5] Creating visualizations...")
    visualize_clusters(X_2d, labels, title="Malware Clusters")

    # Compare with known families if available
    if 'family' in df.columns:
        family_encoder = LabelEncoder()
        family_labels = family_encoder.fit_transform(df['family'])
        compare_with_families(X_2d, labels, family_labels)

    # Analysis
    print("\n[Step 6] Analyzing clusters...")
    analysis = analyze_clusters(df, labels)

    if analysis:
        print_cluster_report(analysis)

    print("\n" + "=" * 60)
    print("Clustering complete!")
    print("=" * 60)


def create_sample_data(filepath: Path):
    """Create sample malware features dataset."""
    np.random.seed(42)

    # Simulate different malware families
    families = ['emotet', 'trickbot', 'ryuk', 'cobalt_strike', 'generic']
    n_samples = 500

    data = []
    for i in range(n_samples):
        family = np.random.choice(families, p=[0.25, 0.20, 0.15, 0.15, 0.25])

        # Family-specific characteristics
        if family == 'emotet':
            file_size = np.random.lognormal(12, 0.5)
            entropy = np.random.normal(7.2, 0.3)
            num_imports = np.random.randint(30, 60)
        elif family == 'trickbot':
            file_size = np.random.lognormal(11, 0.4)
            entropy = np.random.normal(6.8, 0.4)
            num_imports = np.random.randint(40, 80)
        elif family == 'ryuk':
            file_size = np.random.lognormal(13, 0.6)
            entropy = np.random.normal(7.5, 0.2)
            num_imports = np.random.randint(20, 40)
        elif family == 'cobalt_strike':
            file_size = np.random.lognormal(10, 0.3)
            entropy = np.random.normal(7.8, 0.2)
            num_imports = np.random.randint(10, 25)
        else:
            file_size = np.random.lognormal(11.5, 0.8)
            entropy = np.random.normal(6.5, 0.6)
            num_imports = np.random.randint(20, 100)

        data.append({
            'sha256': f'sample_{i:04d}',
            'file_size': int(file_size),
            'entropy': min(8.0, max(0.0, entropy)),
            'num_imports': num_imports,
            'num_sections': np.random.randint(3, 8),
            'has_debug': np.random.choice([0, 1], p=[0.9, 0.1]),
            'has_signature': np.random.choice([0, 1], p=[0.8, 0.2]),
            'imphash': f'hash_{np.random.randint(0, 50):03d}',
            'family': family
        })

    df = pd.DataFrame(data)
    filepath.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(filepath, index=False)
    print(f"Created sample data with {len(df)} samples")


if __name__ == "__main__":
    main()
